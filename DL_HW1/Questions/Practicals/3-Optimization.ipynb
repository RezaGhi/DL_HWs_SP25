{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5fd69e",
   "metadata": {
    "id": "5e5fd69e"
   },
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://www.sharif.ir/documents/20124/0/logo-fa-IR.png/4d9b72bc-494b-ed5a-d3bb-e7dfd319aec8?t=1609608338755\" alt=\"Logo\" width=\"200\">\n",
    "    <p><b>HW1 @ Deep Learning Course, Dr. Soleymani</b></p>\n",
    "    <p><b>ِDesinged by Payam Taebi</b></p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sJ87dPg0aerE",
   "metadata": {
    "id": "sJ87dPg0aerE"
   },
   "source": [
    "\n",
    "*Full Name:*\n",
    "\n",
    "*Student Number:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIJQvTjfMMDK"
   },
   "source": [
    "\n",
    "\n",
    "# Overview(100 Points)\n",
    "\n",
    "This notebook is primarily for exploration rather than heavy implementation. We aim to examine the performance of various optimization methods on different functions. The submission for this exercise is in-person, so please experiment with the parameters in this section to better understand the challenges of each part.\n",
    "\n",
    "We will define several 1D and 2D functions (e.g., Rastrigin, Schwefel, Rosenbrock, Ackley, Beale, Eggholder, Ill-Conditioned Convex functions) using PyTorch. These functions serve as challenging test cases for our optimizers.\n",
    "\n",
    "Implement different optimization algorithms:\n",
    "We cover first-order methods (SGD, SGD with Momentum, Nesterov Accelerated Gradient, Adagrad, RMSprop, Adam, Nadam) and second-order methods (Newton's Method, L-BFGS). Each method's update rule is implemented and explained.\n",
    "\n",
    "These are some of the components we used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmYX4Q6XKiBi"
   },
   "source": [
    "# First Section\n",
    "\n",
    "In the first section, we have a set of functions for demonstration. Do not modify these; they are implemented to display the functions in this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Upm-lioPFXIO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "def plot_1d_function_torch(func, domain, global_x, title=\"1D Function Plot\", initial_x=None, path=None):\n",
    "    \"\"\"\n",
    "    Plot a 1D function (defined in PyTorch) and mark the global minimum.\n",
    "    Optionally, mark an initial point and the optimization path with directional arrows.\n",
    "\n",
    "    Parameters:\n",
    "      - func: a function that accepts a torch tensor and returns a torch tensor.\n",
    "      - domain: tuple (xmin, xmax)\n",
    "      - global_x: x-coordinate of the global minimum.\n",
    "      - title: title for the plot.\n",
    "      - initial_x: (optional) x-coordinate of the initial point.\n",
    "      - path: (optional) a list or numpy array of x-values representing the optimization path.\n",
    "    \"\"\"\n",
    "    x_np = np.linspace(domain[0], domain[1], 1000)\n",
    "    x_torch = torch.tensor(x_np, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        y_torch = func(x_torch)\n",
    "    y_np = y_torch.numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x_np, y_np, lw=2, label=title)\n",
    "\n",
    "    # Mark initial point if provided.\n",
    "    if initial_x is not None:\n",
    "        init_val = func(torch.tensor(initial_x, dtype=torch.float32)).item()\n",
    "        plt.scatter(initial_x, init_val, color='blue', s=80, zorder=5, label='Initial Point')\n",
    "\n",
    "    # Plot the optimization path if provided.\n",
    "    if path is not None:\n",
    "        path = np.array(path)\n",
    "        # Draw a line connecting the points.\n",
    "        y_path = [func(torch.tensor(p, dtype=torch.float32)).item() for p in path]\n",
    "        plt.plot(path, y_path, color='orange', linewidth=2, marker='o', markersize=4, label='Optimization Path')\n",
    "        # Draw arrows for each segment.\n",
    "        for i in range(len(path)-1):\n",
    "            start = path[i]\n",
    "            end = path[i+1]\n",
    "            y_start = func(torch.tensor(start, dtype=torch.float32)).item()\n",
    "            y_end = func(torch.tensor(end, dtype=torch.float32)).item()\n",
    "            plt.annotate(\"\",\n",
    "                         xy=(end, y_end),\n",
    "                         xytext=(start, y_start),\n",
    "                         arrowprops=dict(arrowstyle=\"->\", color='orange', lw=2))\n",
    "\n",
    "    # Mark the global minimum.\n",
    "    global_val = func(torch.tensor(global_x, dtype=torch.float32)).item()\n",
    "    plt.scatter(global_x, global_val, color='red', s=80, zorder=5, label='Global Minimum')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "def plot_2d_contour_torch(func, x_domain, y_domain, global_point, title=\"2D Function Contour\",\n",
    "                            levels=50, cmap='viridis', initial_point=None, path=None):\n",
    "    \"\"\"\n",
    "    Plot a 2D function (defined in PyTorch) using a contour plot, marking the global minimum.\n",
    "    Optionally, mark an initial point and draw the optimization path with arrows indicating direction.\n",
    "\n",
    "    Parameters:\n",
    "      - func: a function that accepts a torch tensor of shape (2, H, W) and returns a tensor of shape (H, W).\n",
    "      - x_domain: tuple (xmin, xmax)\n",
    "      - y_domain: tuple (ymin, ymax)\n",
    "      - global_point: tuple (x*, y*) of the global minimum.\n",
    "      - title: title for the plot.\n",
    "      - levels: number of contour levels.\n",
    "      - cmap: colormap.\n",
    "      - initial_point: (optional) tuple (x0, y0) for the initial point.\n",
    "      - path: (optional) numpy array of shape (n, 2) representing the optimization path.\n",
    "    \"\"\"\n",
    "    x_np = np.linspace(x_domain[0], x_domain[1], 400)\n",
    "    y_np = np.linspace(y_domain[0], y_domain[1], 400)\n",
    "    X_np, Y_np = np.meshgrid(x_np, y_np)\n",
    "\n",
    "    # Create input grid tensor with shape (2, H, W)\n",
    "    grid = torch.tensor(np.stack([X_np, Y_np], axis=0), dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        Z_torch = func(grid)\n",
    "    Z_np = Z_torch.numpy()\n",
    "    vmin, vmax = Z_np.min(), Z_np.max()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cp = plt.contourf(X_np, Y_np, Z_np, levels=levels, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(cp)\n",
    "    plt.contour(X_np, Y_np, Z_np, levels=15, colors='black', alpha=0.5)\n",
    "\n",
    "    # Mark initial point if provided.\n",
    "    if initial_point is not None:\n",
    "        plt.scatter(initial_point[0], initial_point[1], color='blue', s=100, marker='o', label='Initial Point')\n",
    "\n",
    "    # Plot the optimization path if provided.\n",
    "    if path is not None:\n",
    "        path = np.array(path)\n",
    "        plt.plot(path[:, 0], path[:, 1], marker='o', color='orange', markersize=4, linewidth=2, label='Optimization Path')\n",
    "        for i in range(len(path) - 1):\n",
    "            start = path[i]\n",
    "            end = path[i+1]\n",
    "            plt.annotate(\"\",\n",
    "                         xy=(end[0], end[1]),\n",
    "                         xytext=(start[0], start[1]),\n",
    "                         arrowprops=dict(arrowstyle=\"->\", color='orange', lw=2))\n",
    "\n",
    "    # Mark the global minimum.\n",
    "    plt.scatter(global_point[0], global_point[1], color='red', s=100, marker='*', label='Global Minimum')\n",
    "\n",
    "    plt.title(title + \" (Contour Plot)\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_interactive_3d_torch(func, x_domain, y_domain, global_point, title=\"Interactive 3D Plot\",\n",
    "                              colorscale='viridis', initial_point=None, path=None):\n",
    "    \"\"\"\n",
    "    Create an interactive 3D surface plot using Plotly for a 2D function defined in PyTorch.\n",
    "    Assumes the input is a tensor with two channels: first channel for x and second for y.\n",
    "    Optionally, marks an initial point and draws cones (arrows) to indicate direction along the optimization path.\n",
    "\n",
    "    Parameters:\n",
    "      - func: a function that accepts a torch tensor of shape (2, H, W) and returns a tensor of shape (H, W).\n",
    "      - x_domain: tuple (xmin, xmax)\n",
    "      - y_domain: tuple (ymin, ymax)\n",
    "      - global_point: tuple (x*, y*) for the global minimum.\n",
    "      - title: title for the plot.\n",
    "      - colorscale: Plotly colorscale.\n",
    "      - initial_point: (optional) tuple (x0, y0) for the initial point.\n",
    "      - path: (optional) numpy array of shape (n, 2) representing the optimization path.\n",
    "    \"\"\"\n",
    "    # Create grid for the surface.\n",
    "    x_np = np.linspace(x_domain[0], x_domain[1], 200)\n",
    "    y_np = np.linspace(y_domain[0], y_domain[1], 200)\n",
    "    X_np, Y_np = np.meshgrid(x_np, y_np)\n",
    "\n",
    "    # Create grid tensor with shape (2, H, W)\n",
    "    grid = torch.tensor(np.stack([X_np, Y_np], axis=0), dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        Z_torch = func(grid)\n",
    "    Z_np = Z_torch.numpy()\n",
    "\n",
    "    surface = go.Surface(x=X_np, y=Y_np, z=Z_np, colorscale=colorscale, opacity=0.9, name=title)\n",
    "    data = [surface]\n",
    "\n",
    "    # Optionally add initial point.\n",
    "    if initial_point is not None:\n",
    "        init_val = func(torch.tensor([initial_point[0], initial_point[1]], dtype=torch.float32)).item()\n",
    "        scatter_initial = go.Scatter3d(\n",
    "            x=[initial_point[0]],\n",
    "            y=[initial_point[1]],\n",
    "            z=[init_val],\n",
    "            mode='markers',\n",
    "            marker=dict(size=6, color='blue'),\n",
    "            name='Initial Point'\n",
    "        )\n",
    "        data.append(scatter_initial)\n",
    "\n",
    "    # Optionally add optimization path.\n",
    "    if path is not None:\n",
    "        path = np.array(path)\n",
    "        z_path = []\n",
    "        for pt in path:\n",
    "            z_val = func(torch.tensor([pt[0], pt[1]], dtype=torch.float32)).item()\n",
    "            z_path.append(z_val)\n",
    "        scatter_path = go.Scatter3d(\n",
    "            x=path[:, 0],\n",
    "            y=path[:, 1],\n",
    "            z=z_path,\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='orange', width=4),\n",
    "            marker=dict(size=4, color='orange'),\n",
    "            name='Optimization Path'\n",
    "        )\n",
    "        data.append(scatter_path)\n",
    "\n",
    "        # Add cone traces for directional arrows.\n",
    "        cone_x = []\n",
    "        cone_y = []\n",
    "        cone_z = []\n",
    "        cone_u = []\n",
    "        cone_v = []\n",
    "        cone_w = []\n",
    "        for i in range(len(path) - 1):\n",
    "            start = path[i]\n",
    "            end = path[i+1]\n",
    "            cone_x.append(start[0])\n",
    "            cone_y.append(start[1])\n",
    "            # Evaluate z at start.\n",
    "            z_start = func(torch.tensor([start[0], start[1]], dtype=torch.float32)).item()\n",
    "            cone_z.append(z_start)\n",
    "            cone_u.append(end[0] - start[0])\n",
    "            cone_v.append(end[1] - start[1])\n",
    "            z_end = func(torch.tensor([end[0], end[1]], dtype=torch.float32)).item()\n",
    "            cone_w.append(z_end - z_start)\n",
    "        if len(cone_x) > 0:\n",
    "            cone_trace = go.Cone(\n",
    "                x=cone_x,\n",
    "                y=cone_y,\n",
    "                z=cone_z,\n",
    "                u=cone_u,\n",
    "                v=cone_v,\n",
    "                w=cone_w,\n",
    "                sizemode=\"absolute\",\n",
    "                sizeref=0.5,\n",
    "                anchor=\"tail\",\n",
    "                showscale=False,\n",
    "                colorscale=[[0, 'orange'], [1, 'orange']],\n",
    "                name=\"Step Arrows\"\n",
    "            )\n",
    "            data.append(cone_trace)\n",
    "\n",
    "    # Add global minimum.\n",
    "    global_tensor = torch.tensor([global_point[0], global_point[1]], dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        global_z = func(global_tensor).item()\n",
    "    scatter_global = go.Scatter3d(\n",
    "        x=[global_point[0]],\n",
    "        y=[global_point[1]],\n",
    "        z=[global_z],\n",
    "        mode='markers',\n",
    "        marker=dict(size=8, color='red', symbol='diamond'),\n",
    "        name='Global Minimum'\n",
    "    )\n",
    "    data.append(scatter_global)\n",
    "\n",
    "    fig = go.Figure(data=data)\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis_title='x',\n",
    "            yaxis_title='y',\n",
    "            zaxis_title='f(x,y)'\n",
    "        ),\n",
    "        autosize=True\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_loss_vs_epoch(loss_func, path):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a loss function and an optimization path, compute the loss at each epoch and plot it.\n",
    "\n",
    "    Parameters:\n",
    "      - loss_func: A function that accepts a torch tensor representing parameters and returns a scalar loss.\n",
    "      - path: A list or NumPy array of parameter values (e.g. from the optimizer).\n",
    "              Each element should be convertible to a torch tensor.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    # Loop over each parameter value in the path.\n",
    "    for p in path:\n",
    "        # Convert parameter p to a torch tensor (assume float32).\n",
    "        # p can be a 1D array or a multi-dimensional array.\n",
    "        p_tensor = torch.tensor(p, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            loss_val = loss_func(p_tensor).item()\n",
    "        losses.append(loss_val)\n",
    "\n",
    "    epochs = np.arange(len(losses))\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(epochs, losses, marker='o', color='blue', linewidth=2)\n",
    "    plt.title(\"Loss vs. Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAjw8p8FKqcr"
   },
   "source": [
    "# Next Section (18 Points)\n",
    "\n",
    "In the following section, we examine all the functions, each of which presents its own unique challenge. These functions are both one-dimensional and two-dimensional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smXMurxMlYMW"
   },
   "source": [
    "# 1D Rastrigin Function\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x) = x^2 - 10 \\cos\\left(2\\pi x\\right) + 10\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x \\in [-5,\\, 5] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "\\\\( x = 0 \\\\) with \\\\( f(0)=0 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "This function is **non-convex** and exhibits many local minima due to the cosine modulation. Its oscillatory behavior over \\\\( [-5,5] \\\\) makes it a popular test for global optimization methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aj3JwNZya2rZ"
   },
   "outputs": [],
   "source": [
    "# 1D Rastrigin function in PyTorch.\n",
    "def rastrigin_1d_torch(x: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 1D Rastrigin function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot the 1D Rastrigin function.\n",
    "plot_1d_function_torch(rastrigin_1d_torch, [-5, 5], global_x=0, title=\"1D Rastrigin Function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_R4yW7ml0KQ"
   },
   "source": [
    "# 1D Schwefel Function\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x) = 418.9829 - x \\sin\\Bigl(\\sqrt{|x|}\\Bigr)\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x \\in [0,\\, 500] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "Approximately at \\\\( x \\approx 420.9687 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "This function is highly **non-convex** and rugged with many deceptive local minima. Its large domain accentuates the difficulty in escaping local traps, making it a challenging benchmark for optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITGCVgusa2tS"
   },
   "outputs": [],
   "source": [
    "# 1D Schwefel function in PyTorch.\n",
    "def schwefel_1d_torch(x: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 1D Schwefel function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot the 1D Schwefel function.\n",
    "plot_1d_function_torch(schwefel_1d_torch, [0, 500], global_x=420.9687, title=\"1D Schwefel Function\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2qGbJ8Nl42Z"
   },
   "source": [
    "# 1D Ill-Conditioned Convex Function\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x) = \\ln\\Bigl(1 + e^{10x}\\Bigr) + x^2\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x \\in [-5,\\, 5] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "Approximately at \\\\( x \\approx -0.3 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "This function is **convex** (and therefore has a unique global minimum), but it is _ill-conditioned_ because the steep exponential part for \\\\( x > 0 \\\\) creates a rapidly changing gradient. It tests how well an optimizer can adjust its step size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1NQwY4sa2vF"
   },
   "outputs": [],
   "source": [
    "# 1D Ill-Conditioned Convex function in PyTorch.\n",
    "def ill_conditioned_convex_1d_torch(x: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 1D ill-conditioned convex function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot the 1D Ill-Conditioned Convex function.\n",
    "plot_1d_function_torch(ill_conditioned_convex_1d_torch, [-5, 5], global_x=-0.3, title=\"1D Ill-Conditioned Convex Function\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs4YCMZFmB9v"
   },
   "source": [
    "# Rosenbrock Function (2D)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x, y) = (1 - x)^2 + 100 \\,(y - x^2)^2\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x \\in [-2,\\, 2] \\\\) and \\\\( y \\in [-1,\\, 3] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "At \\\\( (x,y) = (1,1) \\\\) with \\\\( f(1,1)=0 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "The Rosenbrock function is **non-convex** despite its smoothness. Its narrow, curved valley makes it challenging for gradient-based optimizers to converge to the global minimum. This function is a classical benchmark for testing optimization algorithms.\n",
    "\n",
    "In the next cells, we plot it both as a static contour and as an interactive 3D plot. We'll also mark an initial point (for example, \\\\( (-1,1.5) \\\\)) and the optimization path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzqERVuBmBI5"
   },
   "outputs": [],
   "source": [
    "# Define the Rosenbrock function for 2D inputs in PyTorch.\n",
    "# The input is a tensor of shape (2, H, W) where the first channel is x and the second is y.\n",
    "def rosenbrock_2d_torch(X: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 2D Rosenbrock function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot using static contour.\n",
    "plot_2d_contour_torch(rosenbrock_2d_torch, [-2, 2], [-1, 3], global_point=(1, 1),\n",
    "                      title=\"Rosenbrock Function (2D)\")\n",
    "\n",
    "# Plot using interactive 3D.\n",
    "plot_interactive_3d_torch(rosenbrock_2d_torch, [-2, 2], [-1, 3], global_point=(1, 1),\n",
    "                          title=\"Interactive 3D Rosenbrock Function\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf-LTGmhYtYI"
   },
   "source": [
    "# 2D Rastrigin Function\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x, y) = x^2 + y^2 - 10 \\Bigl[\\cos\\left(2\\pi x\\right) + \\cos\\left(2\\pi y\\right)\\Bigr] + 20\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x, y \\in [-5,\\, 5] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "At \\\\( (0,0) \\\\) with \\\\( f(0,0)=0 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "The 2D Rastrigin function is highly **non-convex** and multimodal, featuring many local minima. Its oscillatory behavior in both dimensions makes it a demanding test for optimization techniques.\n",
    "\n",
    "Below, we display both the static contour and interactive 3D plots with an example initial point (e.g., \\\\( (3,3) \\\\)) and a dummy optimization path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTCSiYLqYvFR"
   },
   "outputs": [],
   "source": [
    "# Define the 2D Rastrigin function in PyTorch.\n",
    "def rastrigin_2d_torch(X: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 2D Rastrigin function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot as a static contour.\n",
    "plot_2d_contour_torch(rastrigin_2d_torch, [-5, 5], [-5, 5], global_point=(0, 0),\n",
    "                      title=\"2D Rastrigin Function\", cmap='plasma')\n",
    "\n",
    "# Plot as an interactive 3D surface.\n",
    "plot_interactive_3d_torch(rastrigin_2d_torch, [-5, 5], [-5, 5], global_point=(0, 0),\n",
    "                          title=\"Interactive 3D Rastrigin Function\", colorscale='plasma')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQfFakkSYtap"
   },
   "source": [
    "# Ackley Function (2D)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x, y) = -20 \\exp\\!\\left(-0.2 \\sqrt{\\frac{x^2+y^2}{2}}\\right) - \\exp\\!\\left(\\frac{\\cos\\left(2\\pi x\\right)+\\cos\\left(2\\pi y\\right)}{2}\\right) + 20 + e\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x, y \\in [-5,\\, 5] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "At \\\\( (0,0) \\\\) with \\\\( f(0,0)=0 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "The Ackley function features a nearly flat outer region with a deep, narrow central pit, creating a challenging landscape for optimization algorithms. This function is popular for testing global optimization techniques.\n",
    "\n",
    "We now show both the contour and interactive 3D plots with an initial point (e.g., \\\\( (3,3) \\\\)) and an optimization path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJSmNBCZY55h"
   },
   "outputs": [],
   "source": [
    "# Define the 2D Ackley function in PyTorch.\n",
    "def ackley_2d_torch(X: torch.Tensor, a=20, b=0.2, c=2*np.pi) -> torch.Tensor:\n",
    "    # TODO: Implement the 2D Ackley function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot as a static contour.\n",
    "plot_2d_contour_torch(ackley_2d_torch, [-5, 5], [-5, 5], global_point=(0, 0),\n",
    "                      title=\"Ackley Function (2D)\", cmap='inferno')\n",
    "\n",
    "# Plot as an interactive 3D surface.\n",
    "plot_interactive_3d_torch(ackley_2d_torch, [-5, 5], [-5, 5], global_point=(0, 0),\n",
    "                          title=\"Interactive 3D Ackley Function\", colorscale='inferno')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Z9KNdHsYtfH"
   },
   "source": [
    "# Beale Function (2D)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x, y) = \\left(1.5 - x + xy\\right)^2 + \\left(2.25 - x + xy^2\\right)^2 + \\left(2.625 - x + xy^3\\right)^2\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x, y \\in [-4.5,\\, 4.5] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "At \\\\( (3, 0.5) \\\\) with \\\\( f(3,0.5)=0 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "The Beale function is **non-convex** with several local minima, making it a classical benchmark for global optimization. Its complex structure challenges optimizers in 2D space.\n",
    "\n",
    "Below, we provide both a static contour and an interactive 3D plot with an initial point (e.g., \\\\( (0,0) \\\\)) and an optimization path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgxBtD0XZCsJ"
   },
   "outputs": [],
   "source": [
    "# Define the 2D Beale function in PyTorch.\n",
    "def beale_2d_torch(X: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 2D Beale function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot as a static contour.\n",
    "plot_2d_contour_torch(beale_2d_torch, [-4.5, 4.5], [-4.5, 4.5], global_point=(3, 0.5),\n",
    "                      title=\"Beale Function (2D)\", cmap='Spectral')\n",
    "\n",
    "# Plot as an interactive 3D surface.\n",
    "plot_interactive_3d_torch(beale_2d_torch, [-4.5, 4.5], [-4.5, 4.5], global_point=(3, 0.5),\n",
    "                          title=\"Interactive 3D Beale Function\", colorscale='Spectral')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uI84q3nqYthc"
   },
   "source": [
    "# Eggholder Function (2D)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x, y) = - (y+47) \\sin\\!\\left(\\sqrt{\\left|\\frac{x}{2} + (y+47)\\right|}\\right) - x \\sin\\!\\left(\\sqrt{\\left|x - (y+47)\\right|}\\right)\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x, y \\in [-512,\\, 512] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "Approximately at \\\\( (512,\\, 404.2319) \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "The Eggholder function is extremely **non-convex** with a rugged, highly oscillatory landscape that contains many local minima. It is one of the most challenging test functions in optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1cvpJUtZTTj"
   },
   "outputs": [],
   "source": [
    "# Define the 2D Eggholder function in PyTorch.\n",
    "def eggholder_2d_torch(X: torch.Tensor) -> torch.Tensor:\n",
    "    # TODO: Implement the 2D Eggholder function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot as a static contour.\n",
    "plot_2d_contour_torch(eggholder_2d_torch, [-512, 512], [-512, 512], global_point=(512, 404.2319),\n",
    "                      title=\"Eggholder Function (2D)\", cmap='inferno')\n",
    "\n",
    "# Plot as an interactive 3D surface.\n",
    "plot_interactive_3d_torch(eggholder_2d_torch, [-512, 512], [-512, 512], global_point=(512, 404.2319),\n",
    "                          title=\"Interactive 3D Eggholder Function\", colorscale='inferno')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_jSswuwYtkH"
   },
   "source": [
    "# Ill-Conditioned Convex Function (2D)\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\n",
    "$$\n",
    "f(x, y) = 100 \\Bigl(x\\cos\\theta - y\\sin\\theta\\Bigr)^2 + \\Bigl(x\\sin\\theta + y\\cos\\theta\\Bigr)^2 \\quad \\text{with } \\theta = \\frac{\\pi}{6}\n",
    "$$\n",
    "\n",
    "**Domain:**  \n",
    "\\\\( x, y \\in [-5,\\, 5] \\\\)\n",
    "\n",
    "**Global Minimum:**  \n",
    "At \\\\( (0,0) \\\\) with \\\\( f(0,0)=0 \\\\)\n",
    "\n",
    "**Explanation:**  \n",
    "This function is **convex** (thus it has a unique global minimum) but is _ill-conditioned_ due to the rotation and different scaling along the rotated axes. Its behavior tests an optimizer’s ability to deal with steep versus flat directions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGdz98dfZhVC"
   },
   "outputs": [],
   "source": [
    "# Define the 2D Ill-Conditioned Convex function in PyTorch.\n",
    "def ill_conditioned_convex_2d_torch(X: torch.Tensor, theta=torch.tensor(np.pi/6)) -> torch.Tensor:\n",
    "    # TODO: Implement the 2D ill-conditioned convex function using PyTorch operations\n",
    "    pass\n",
    "\n",
    "# Plot as a static contour.\n",
    "plot_2d_contour_torch(ill_conditioned_convex_2d_torch, [-5, 5], [-5, 5], global_point=(0, 0),\n",
    "                      title=\"Ill-Conditioned Convex Function (2D)\", cmap='viridis')\n",
    "\n",
    "# Plot as an interactive 3D surface.\n",
    "plot_interactive_3d_torch(ill_conditioned_convex_2d_torch, [-5, 5], [-5, 5], global_point=(0, 0),\n",
    "                          title=\"Interactive 3D Ill-Conditioned Convex Function (2D)\", colorscale='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoK5omVIK8Ru"
   },
   "source": [
    "# Question (12 Points)\n",
    "\n",
    "For each of the functions presented above, what unique challenges do you think they offer? Consider aspects such as steep gradients, saddle points, local minima, flat regions, and other characteristics that could affect the optimization process.\n",
    "\n",
    "Please provide a brief explanation for each function, describing the potential difficulties in learning or optimizing it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5LWqXSXYtmc"
   },
   "source": [
    "# Implementing an Optimization Method (5 Points)\n",
    "\n",
    "Now that we've discussed the general structure of our optimization function, let's explore how to implement a specific optimization method. In this section, we'll walk through the steps required to define an update rule for an optimizer. This involves:\n",
    "\n",
    "1. **Computing the Loss and its Derivatives:**  \n",
    "   We evaluate the loss function for the current parameters, compute the gradient, and optionally calculate the Hessian if using a second-order method.\n",
    "\n",
    "2. **Applying the Update Rule:**  \n",
    "   Based on the computed derivatives, we update the parameters using the specific logic of our chosen optimization method (e.g., adjusting the parameters using SGD, Adam, or Newton's method).\n",
    "\n",
    "3. **Maintaining State:**  \n",
    "   For methods that require momentum or other historical data, we update and maintain a state dictionary that carries this information from one iteration to the next.\n",
    "\n",
    "By following these steps, we can iteratively update the parameters to minimize the loss function and analyze the optimization trajectory. Let's move on to see this process in action.\n",
    "\n",
    "# General Optimization Function Explanation\n",
    "\n",
    "The `optimize` function provides a unified framework for iterative optimization methods. Whether using first-order (gradient-based) or second-order (Hessian-based) methods, the overall process remains similar: we start with an initial guess for the parameters and then iteratively update these parameters in order to minimize a given loss function.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **Initialization:**\n",
    "   - **Parameters:**  \n",
    "     The function receives an initial parameter tensor (`initial_params`). This tensor is cloned and set to require gradients so that we can compute derivatives with respect to it.\n",
    "   - **State Storage:**  \n",
    "     An empty dictionary `state` is initialized to store any additional information required by the update method (e.g., momentum for Adam, or curvature approximations for second-order methods).\n",
    "   - **Path Recording:**  \n",
    "     The initial parameters are stored in a list called `path`. This list will hold the parameter values after each iteration, allowing us to visualize the optimization trajectory later.\n",
    "\n",
    "2. **Iterative Update Process:**\n",
    "   - For each epoch (i.e., optimization step), the following steps occur:\n",
    "     1. **Loss Evaluation:**  \n",
    "        The loss function `loss_func` is evaluated at the current parameter values to determine how well the current parameters perform.\n",
    "     2. **Gradient Computation:**  \n",
    "        The gradient (first derivative) of the loss with respect to the parameters is computed using `loss.backward()`.  \n",
    "        - For **first-order methods**, only the gradient is used.\n",
    "        - For **second-order methods**, additional curvature information is needed.\n",
    "     3. **Hessian Computation (Optional):**  \n",
    "        If the `second_order` flag is set to `True`, the Hessian (matrix of second derivatives) is computed using PyTorch's `torch.autograd.functional.hessian`.  \n",
    "        This Hessian provides insight into the curvature of the loss surface and is useful for methods like Newton's method.\n",
    "     4. **Parameter Update:**  \n",
    "        The update function `update_func` is then called:\n",
    "        - For **first-order methods** (e.g., SGD, Adam):  \n",
    "          It is called with the current parameters, their gradient, the state, and hyperparameters.\n",
    "        - For **second-order methods** (e.g., Newton’s Method, L-BFGS):  \n",
    "          The computed Hessian is also passed.\n",
    "        This function returns updated parameter values and an updated state.\n",
    "     5. **Re-enable Gradient Tracking:**  \n",
    "        After the update, gradients are cleared and re-enabled for the next iteration.\n",
    "     6. **Path Recording:**  \n",
    "        The new parameters are added to the `path` list.\n",
    "\n",
    "3. **Return Value:**\n",
    "   - After completing all epochs, the function returns the `path` — a list of parameter values at each iteration. This path can later be used to visualize the optimization trajectory (for example, by plotting the loss versus epochs or overlaying the path on the loss surface).\n",
    "\n",
    "## Common Underlying Principles\n",
    "\n",
    "- **Unified Structure:**  \n",
    "  All optimization methods follow a similar iterative procedure: compute the loss, compute the gradient (and optionally the Hessian), update the parameters, and record the progress.\n",
    "  \n",
    "- **First-Order vs. Second-Order Methods:**  \n",
    "  - *First-Order Methods* use only the gradient information. Their update rule typically has the form:  \n",
    "  $$\n",
    "    w_{t+1} = w_t - \\eta \\nabla f(w_t)\n",
    "  $$\n",
    "  - *Second-Order Methods* also incorporate curvature information (via the Hessian) to adjust the step direction and size:  \n",
    "    $$ w_{t+1} = w_t - \\left( H(w_t) + \\epsilon I \\right)^{-1} \\nabla f(w_t) $$\n",
    "  The `second_order` flag in our function determines whether the Hessian is computed and passed to the update function.\n",
    "\n",
    "- **State Management:**  \n",
    "  Many advanced optimizers (like Adam, RMSprop, or L-BFGS) maintain a state that includes historical information (e.g., moving averages of gradients, momentum, or curvature approximations). This state is updated at each iteration and passed to the update function to help guide the parameter updates.\n",
    "\n",
    "In summary, the `optimize` function abstracts the common iterative process of optimization, allowing us to plug in different update functions (each corresponding to a different optimization method) and compare their performance on the same problem. This modular approach makes it straightforward to experiment with a wide range of optimization algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6FpMyx8iRWt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def optimize(loss_func, update_func, initial_params, epochs, hyperparams, second_order=False):\n",
    "    \"\"\"\n",
    "    General optimization function supporting both first-order (gradient-based)\n",
    "    and second-order (Hessian-based) optimization methods.\n",
    "\n",
    "    Parameters:\n",
    "        - loss_func: Function to minimize. Accepts parameters and returns loss.\n",
    "        - update_func: Function that updates parameters.\n",
    "                       Signature (first-order): (params, grad, state, hyperparams) -> (new_params, new_state)\n",
    "                       Signature (second-order): (params, grad, state, hyperparams, hessian) -> (new_params, new_state)\n",
    "        - initial_params: Torch tensor representing the initial parameter values.\n",
    "        - epochs: Number of optimization steps.\n",
    "        - hyperparams: Dictionary of hyperparameters.\n",
    "        - second_order: Boolean flag indicating if second-order derivatives (Hessian) are needed.\n",
    "\n",
    "    Returns:\n",
    "        - path: List of parameter values at each step.\n",
    "    \"\"\"\n",
    "    params = initial_params.clone().detach().requires_grad_(True)\n",
    "    state = {}  # Store state (e.g., momentum, Hessian approximations, etc.)\n",
    "    path = [params.clone().detach().numpy()]  # Store initial point\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = loss_func(params)  # Compute loss\n",
    "        loss.backward()  # Compute gradient\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient tracking during updates\n",
    "            if second_order:\n",
    "                # TODO: Compute the Hessian matrix using torch.autograd.functional.hessian\n",
    "                hessian = None  # Replace with actual computation\n",
    "\n",
    "                # TODO: Update parameters using the update_func with second-order information\n",
    "                params, state = None  # Replace with actual update function call\n",
    "            else:\n",
    "                # TODO: Update parameters using the update_func with first-order information\n",
    "                params, state = None  # Replace with actual update function call\n",
    "\n",
    "            params.requires_grad_(True)  # Re-enable gradient computation\n",
    "\n",
    "        path.append(params.clone().detach().numpy())  # Store new point\n",
    "\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIN2LRKlM3IK"
   },
   "source": [
    "# Optimization Demonstration Functions\n",
    "\n",
    "Next, we have a set of functions that display the optimization process by running it on all the functions. You may edit them if needed for better visualization, but preferably, do not modify these two sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PDjwmdrmYFm"
   },
   "outputs": [],
   "source": [
    "def optimize_and_plot(loss_func, update_func, initial_params, epochs, hyperparams, x_domain, y_domain=None, title=\"Optimization\" ,second_order=False):\n",
    "    \"\"\"\n",
    "    Perform optimization and automatically visualize the results for 1D or 2D functions.\n",
    "\n",
    "    Parameters:\n",
    "      - loss_func: Function to minimize. It accepts parameters and returns a scalar loss.\n",
    "      - update_func: Function that updates parameters. Signature: (params, grad, state, hyperparams) -> (new_params, new_state)\n",
    "      - initial_params: Torch tensor representing the initial parameter values.\n",
    "      - epochs: Number of optimization steps.\n",
    "      - hyperparams: Dictionary of hyperparameters for the update function.\n",
    "      - x_domain: Tuple (xmin, xmax) defining the domain for plotting.\n",
    "      - y_domain: Tuple (ymin, ymax) defining the domain for 2D functions (set to None for 1D).\n",
    "      - title: Title for the plots.\n",
    "\n",
    "    Returns:\n",
    "      - path: The list of parameter values at each epoch (for further processing if desired).\n",
    "    \"\"\"\n",
    "    # Run the optimization (assumes a separate \"optimize\" function exists).\n",
    "    path = optimize(loss_func, update_func, initial_params, epochs, hyperparams , second_order=second_order)\n",
    "    path_np = np.array(path)  # Convert list of torch tensors (or arrays) to a NumPy array.\n",
    "    initial_np = initial_params.detach().numpy()  # Get initial point as a NumPy array.\n",
    "\n",
    "    # Check dimensionality: if initial_params has shape (1, ...) then it's 1D; if (2, ...) then 2D.\n",
    "    if initial_params.shape[0] == 1:\n",
    "        # 1D case: Pass initial_x and path.\n",
    "        plot_1d_function_torch(\n",
    "            func=loss_func,\n",
    "            domain=x_domain,\n",
    "            global_x=path_np[-1][0],\n",
    "            title=title,\n",
    "            initial_x=initial_np[0],\n",
    "            path=path_np\n",
    "        )\n",
    "        plot_loss_vs_epoch(loss_func, path_np)\n",
    "    elif initial_params.shape[0] == 2:\n",
    "        # 2D case: Pass initial_point as a tuple and the full path.\n",
    "        plot_2d_contour_torch(\n",
    "            func=loss_func,\n",
    "            x_domain=x_domain,\n",
    "            y_domain=y_domain,\n",
    "            global_point=(path_np[-1][0], path_np[-1][1]),\n",
    "            title=title,\n",
    "            initial_point=(initial_np[0], initial_np[1]),\n",
    "            path=path_np\n",
    "        )\n",
    "        plot_interactive_3d_torch(\n",
    "            func=loss_func,\n",
    "            x_domain=x_domain,\n",
    "            y_domain=y_domain,\n",
    "            global_point=(path_np[-1][0], path_np[-1][1]),\n",
    "            title=title,\n",
    "            initial_point=(initial_np[0], initial_np[1]),\n",
    "            path=path_np\n",
    "        )\n",
    "        plot_loss_vs_epoch(loss_func, path_np)\n",
    "    else:\n",
    "        raise ValueError(\"Function must be either 1D or 2D.\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZ84cDiT-efX"
   },
   "outputs": [],
   "source": [
    "def run_all_optimizations(update_func, hyperparams, epochs,second_order=False):\n",
    "    \"\"\"\n",
    "    Run optimization for all benchmark functions (both 1D and 2D) using the provided update function,\n",
    "    hyperparameters, and epoch count. It calls `optimize_and_plot` to handle visualization.\n",
    "\n",
    "    Parameters:\n",
    "      - update_func: The update function to use (e.g., adam_update, sgd_update, etc.).\n",
    "      - hyperparams: Dictionary of hyperparameters for the update function.\n",
    "      - epochs: Number of optimization steps to perform.\n",
    "    \"\"\"\n",
    "    # List of benchmark function configurations.\n",
    "    configs = [\n",
    "        # 1D Functions\n",
    "        {\n",
    "            \"title\": \"1D Rastrigin Function Optimization\",\n",
    "            \"loss_func\": rastrigin_1d_torch,\n",
    "            \"initial_params\": torch.tensor([3.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-5, 5),\n",
    "            \"y_domain\": None\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"1D Schwefel Function Optimization\",\n",
    "            \"loss_func\": schwefel_1d_torch,\n",
    "            \"initial_params\": torch.tensor([100.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (0, 500),\n",
    "            \"y_domain\": None\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"1D Ill-Conditioned Convex Function Optimization\",\n",
    "            \"loss_func\": ill_conditioned_convex_1d_torch,\n",
    "            \"initial_params\": torch.tensor([3.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-5, 5),\n",
    "            \"y_domain\": None\n",
    "        },\n",
    "        # 2D Functions\n",
    "        {\n",
    "            \"title\": \"2D Rosenbrock Function Optimization\",\n",
    "            \"loss_func\": rosenbrock_2d_torch,\n",
    "            \"initial_params\": torch.tensor([-1.0, 1.5], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-2, 2),\n",
    "            \"y_domain\": (-1, 3)\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2D Rastrigin Function Optimization\",\n",
    "            \"loss_func\": rastrigin_2d_torch,\n",
    "            \"initial_params\": torch.tensor([3.0, 3.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-5, 5),\n",
    "            \"y_domain\": (-5, 5)\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2D Ackley Function Optimization\",\n",
    "            \"loss_func\": ackley_2d_torch,\n",
    "            \"initial_params\": torch.tensor([3.0, 3.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-5, 5),\n",
    "            \"y_domain\": (-5, 5)\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2D Beale Function Optimization\",\n",
    "            \"loss_func\": beale_2d_torch,\n",
    "            \"initial_params\": torch.tensor([-3.0, 3.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-4.5, 4.5),\n",
    "            \"y_domain\": (-4.5, 4.5)\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2D Eggholder Function Optimization\",\n",
    "            \"loss_func\": eggholder_2d_torch,\n",
    "            \"initial_params\": torch.tensor([0.0, 0.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-512, 512),\n",
    "            \"y_domain\": (-512, 512)\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"2D Ill-Conditioned Convex Function Optimization\",\n",
    "            \"loss_func\": ill_conditioned_convex_2d_torch,\n",
    "            \"initial_params\": torch.tensor([4.0, -3.0], dtype=torch.float32, requires_grad=True),\n",
    "            \"x_domain\": (-5, 5),\n",
    "            \"y_domain\": (-5, 5)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Iterate over each function and call optimize_and_plot\n",
    "    for config in configs:\n",
    "        print(\"Optimizing:\", config[\"title\"])\n",
    "\n",
    "        optimize_and_plot(\n",
    "            loss_func=config[\"loss_func\"],\n",
    "            update_func=update_func,\n",
    "            initial_params=config[\"initial_params\"],\n",
    "            epochs=epochs,\n",
    "            hyperparams=hyperparams,\n",
    "            x_domain=config[\"x_domain\"],\n",
    "            y_domain=config[\"y_domain\"],\n",
    "            title=config[\"title\"],\n",
    "            second_order=second_order\n",
    "        )\n",
    "\n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsdVw8NLNFuC"
   },
   "source": [
    "# Implementation of Optimization Algorithms\n",
    "\n",
    "Now that the optimization functions have been implemented, in this section we will implement various optimization algorithms. Some parts of these algorithms need to be implemented by you, while other parts have already been provided.\n",
    "\n",
    "For each algorithm, experiment with different parameters and fine-tune them to achieve the best possible performance. The selection and tuning of these parameters are part of your grade, and the number of times you experiment with various settings is a crucial component of this exercise.\n",
    "\n",
    "After implementing each algorithm, please submit a report detailing your observations and findings. Make sure to document your parameter tuning process and the performance outcomes for each algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZTlCjY0E8oR"
   },
   "source": [
    "# Stochastic Gradient Descent (SGD)(5 Points)\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\eta \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\(w_t\\\\) is the parameter vector at iteration \\\\(t\\\\),\n",
    "- \\\\(\\eta\\\\) is the learning rate, and\n",
    "- \\\\(\\nabla f(w_t)\\\\) is the gradient of the loss function evaluated at \\\\(w_t\\\\).\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is a fundamental first-order optimization method that updates the parameters in the opposite direction of the gradient. At each iteration, the update rule moves the parameters by a small step proportional to the gradient and the learning rate. This method is widely used because of its simplicity and efficiency, particularly when dealing with large datasets. However, its performance heavily depends on the proper tuning of the learning rate; if set too high, the algorithm might overshoot minima, and if too low, convergence can be very slow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CR_FpRrsghO"
   },
   "outputs": [],
   "source": [
    "def sgd_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    SGD update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to the parameters.\n",
    "      - state: Dictionary to store any state (unused in SGD).\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain \"lr\" (learning rate).\n",
    "      - **kwargs: Additional arguments (ignored for SGD).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameters.\n",
    "      - state: Unchanged state (empty dictionary).\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]  # Get the learning rate from hyperparameters.\n",
    "\n",
    "    # TODO: Implement the standard SGD update rule\n",
    "    new_params = None  # Replace with actual computation\n",
    "\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGXN81GJFHIu"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for SGD (adjust the learning rate as needed).\n",
    "sgd_hyperparams = {\"lr\": 0.01}\n",
    "\n",
    "# Run optimizations for all benchmark functions using SGD.\n",
    "run_all_optimizations(update_func=sgd_update, hyperparams=sgd_hyperparams, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESRhsIjkOjYs"
   },
   "source": [
    "# SGD Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the SGD optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    sgd_hyperparams = {\"lr\": 0.01}\n",
    "\n",
    "In this section, you are required to test various learning rates and analyze how they affect the optimizer's performance. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the learning rate values you tested. Provide a clear list or table of these values.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different learning rates impact the convergence behavior of SGD?\n",
    "   - Were there any specific learning rates that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested learning rates cause the optimizer to get stuck in local minima?\n",
    "\n",
    "3. **Optimal Learning Rate:**\n",
    "   - Which learning rate, among those tested, achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider this learning rate optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying the learning rate. For instance, did higher learning rates lead to faster initial convergence at the risk of overshooting, or did lower learning rates provide more stable but slower convergence?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate when using SGD in similar optimization tasks?\n",
    "\n",
    "Make sure your report includes detailed observations, a comparative analysis, and a summary of all the learning rates tested. Your analysis should clearly illustrate how the choice of learning rate influences the performance of the SGD optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sldK0pfHNBm"
   },
   "source": [
    "# SGD with Momentum (5 Points)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "The SGD with Momentum update is given by:\n",
    "\n",
    "$$\n",
    "v_t = \\beta v_{t-1} + \\eta \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - v_t\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- \\\\(w_t\\\\) is the parameter vector at iteration \\\\(t\\\\),  \n",
    "- \\\\(v_t\\\\) is the velocity (accumulated momentum) at iteration \\\\(t\\\\),  \n",
    "- \\\\(\\eta\\\\) is the learning rate, and  \n",
    "- \\\\(\\beta\\\\) is the momentum coefficient (typically between 0 and 1).\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "SGD with Momentum introduces an additional term \\\\(v_t\\\\) that accumulates a running average of past gradients. This helps dampen oscillations and accelerates convergence, especially in scenarios where the gradient direction is consistent. However, careful tuning of both the learning rate \\\\(\\eta\\\\) and the momentum coefficient \\\\(\\beta\\\\) is necessary for optimal performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umXqXtHbF4CJ"
   },
   "outputs": [],
   "source": [
    "def momentum_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    SGD with Momentum update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to the parameters.\n",
    "      - state: Dictionary to store state (e.g., velocity). Initially, this can be empty.\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "          \"lr\": learning rate, and\n",
    "          \"momentum\": momentum coefficient.\n",
    "      - **kwargs: Additional arguments (not used here).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameters.\n",
    "      - state: Updated state dictionary (contains the velocity).\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]\n",
    "    momentum = hyperparams[\"momentum\"]\n",
    "\n",
    "    if \"v\" not in state:\n",
    "        # TODO: Initialize the velocity tensor with zeros, having the same shape as params\n",
    "        state[\"v\"] = None  # Replace with correct initialization\n",
    "\n",
    "    # TODO: Implement the momentum update rule: v_t = momentum * v_{t-1} + lr * grad\n",
    "    state[\"v\"] = None  # Replace with actual update computation\n",
    "\n",
    "    # TODO: Update parameters using the velocity term\n",
    "    new_params = None  # Replace with actual parameter update\n",
    "\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnUgXIssF6Ol"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for SGD with Momentum.\n",
    "momentum_hyperparams = {\n",
    "    \"lr\": 0.001,       # learning rate\n",
    "    \"momentum\": 0.9    # momentum coefficient\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using SGD with Momentum.\n",
    "run_all_optimizations(update_func=momentum_update, hyperparams=momentum_hyperparams, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeaRKyEDOubj"
   },
   "source": [
    "# Momentum Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the Momentum optimizer, the hyperparameters are defined as follows:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "momentum_hyperparams = {\n",
    "    \"lr\": 0.001,       # learning rate\n",
    "    \"momentum\": 0.9    # momentum coefficient\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this section, you are required to test various values for both the learning rate and the momentum coefficient, and analyze their impact on the optimizer's performance. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. Parameter Variation:\n",
    "   - List all the learning rate values you tested.\n",
    "   - List all the momentum coefficient values you tested.\n",
    "   - Provide a clear list or table of these values along with any combinations you experimented with.\n",
    "\n",
    "2. Performance Analysis:\n",
    "   - How did changes in the learning rate affect the convergence behavior of the Momentum optimizer?\n",
    "   - How did variations in the momentum coefficient influence the optimization process?\n",
    "   - Were there specific combinations that led to faster convergence or instability (e.g., overshooting or slow progress)?\n",
    "\n",
    "3. Optimal Parameter Combination:\n",
    "   - Which combination of learning rate and momentum coefficient achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider this combination optimal based on your observations.\n",
    "\n",
    "4. Trade-offs and Observations:\n",
    "   - Discuss any trade-offs observed when tuning these parameters. For example, did a higher momentum help accelerate convergence at the risk of overshooting, or did a lower momentum lead to more stable but slower updates?\n",
    "   - Describe any trends or patterns that emerged from your experiments.\n",
    "\n",
    "5. Recommendations:\n",
    "   - Based on your experimental results, what recommendations would you give for selecting learning rate and momentum values when using momentum-based optimization methods in similar tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all the hyperparameter values tested. Your analysis should clearly illustrate how the choice of learning rate and momentum coefficient influences the performance of the Momentum optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QYRrs-VJN1c"
   },
   "source": [
    "# Nesterov Accelerated Gradient (NAG)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "The Nesterov Accelerated Gradient update is given by:\n",
    "\n",
    "$$\n",
    "v_t = \\beta \\, v_{t-1} + \\eta \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\beta \\, v_{t-1} - \\eta \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\( w_t \\\\) is the parameter vector at iteration \\\\( t \\\\),\n",
    "- \\\\( v_t \\\\) is the velocity (accumulated momentum) at iteration \\\\( t \\\\),\n",
    "- \\\\( \\eta \\\\) is the learning rate, and\n",
    "- \\\\( \\beta \\\\) is the momentum coefficient (typically a value between 0 and 1).\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Nesterov Accelerated Gradient (NAG) is a variant of SGD with momentum that computes the gradient at a \"lookahead\" position. Instead of computing the gradient at the current parameter \\\\( w_t \\\\) only, NAG uses the accumulated momentum from previous iterations to “look ahead” before updating the parameters. The update can be interpreted as:\n",
    "\n",
    "1. **Compute the momentum update:**  \n",
    "   \\\\( v_t = \\beta \\, v_{t-1} + \\eta \\, \\nabla f(w_t) \\\\)\n",
    "2. **Update the parameters using the previous momentum:**  \n",
    "   \\\\( w_{t+1} = w_t - \\beta \\, v_{t-1} - \\eta \\, \\nabla f(w_t) \\\\)\n",
    "\n",
    "This \"lookahead\" strategy often leads to faster convergence compared to standard momentum because it anticipates the effect of momentum and adjusts the update accordingly.\n",
    "\n",
    "*Note:* In our implementation, we assume that we cannot recompute the gradient at the lookahead position (for simplicity) so we approximate NAG with the following update:\n",
    "\n",
    "$$\n",
    "v_{\\text{prev}} = v_{t-1} \\quad,\\quad v_t = \\beta \\, v_{t-1} + \\eta \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\beta \\, v_{\\text{prev}} - \\eta \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "This formulation uses the previous momentum term directly for the \"lookahead\" component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDQvhoyArOw4"
   },
   "outputs": [],
   "source": [
    "def nag_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    Nesterov Accelerated Gradient (NAG) update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to params.\n",
    "      - state: Dictionary to store the momentum (velocity). Initially empty.\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "            \"lr\": learning rate, and\n",
    "            \"momentum\": momentum coefficient.\n",
    "      - **kwargs: Additional arguments (ignored for NAG).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameter values.\n",
    "      - state: Updated state dictionary containing the velocity.\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]\n",
    "    momentum = hyperparams[\"momentum\"]\n",
    "\n",
    "    # Initialize the velocity if not already in state.\n",
    "    if \"v\" not in state:\n",
    "        state[\"v\"] = torch.zeros_like(params)\n",
    "\n",
    "    # Save the previous velocity for the lookahead.\n",
    "    v_prev = state[\"v\"].clone()\n",
    "    # Update the velocity.\n",
    "    state[\"v\"] = momentum * state[\"v\"] + lr * grad\n",
    "    # Update the parameters using the lookahead formula.\n",
    "    new_params = params - momentum * v_prev - lr * grad\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUmOpdw9GLU2"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for Nesterov Accelerated Gradient.\n",
    "nag_hyperparams = {\n",
    "    \"lr\": 0.001,        # Learning rate\n",
    "    \"momentum\": 0.9     # Momentum coefficient\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using NAG.\n",
    "run_all_optimizations(update_func=nag_update, hyperparams=nag_hyperparams, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNFNBxUSQvOe"
   },
   "source": [
    "# NAG Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the Nesterov Accelerated Gradient (NAG) optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    nag_hyperparams = {\n",
    "        \"lr\": 0.001,        # Learning rate\n",
    "        \"momentum\": 0.9     # Momentum coefficient\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various learning rates and momentum values to analyze how they affect the performance of NAG. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the learning rate and momentum values you tested. Provide a clear list or table of these values.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did varying the learning rate and momentum coefficient impact the convergence behavior of NAG?\n",
    "   - Were there any specific combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested parameter combinations cause the optimizer to get trapped in local minima?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of learning rate and momentum achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying both the learning rate and momentum. For example, did higher momentum values speed up convergence but risk overshooting, or did lower momentum values result in more stable but slower convergence?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate and momentum when using NAG in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the NAG optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRT-aFgZKa8F"
   },
   "source": [
    "# Adagrad (Adaptive Gradient)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "Adagrad adapts the learning rate for each parameter individually by accumulating the squared gradients. Its update equations are:\n",
    "\n",
    "$$\n",
    "G_t = G_{t-1} + \\left(\\nabla f(w_t)\\right)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\frac{\\eta}{\\sqrt{G_t} + \\epsilon} \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- \\\\(w_t\\\\) is the parameter vector at iteration \\\\(t\\\\),  \n",
    "- \\\\(G_t\\\\) is the accumulation of squared gradients (applied elementwise),  \n",
    "- \\\\(\\eta\\\\) is the learning rate, and  \n",
    "- \\\\(\\epsilon\\\\) is a small constant added for numerical stability.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Adagrad adjusts the learning rate based on the history of gradients. Parameters with high gradients accumulate a larger \\\\(G_t\\\\) and thus receive a smaller effective learning rate, while parameters with small or sparse gradients receive larger updates. This makes Adagrad particularly useful for problems with sparse features, but note that its learning rate can decay too aggressively over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laNX8UNNrOw5"
   },
   "outputs": [],
   "source": [
    "def adagrad_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    Adagrad update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to the parameters.\n",
    "      - state: Dictionary to store state (e.g., accumulated squared gradients).\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "          \"lr\": learning rate, and\n",
    "          \"eps\": a small constant for numerical stability.\n",
    "      - **kwargs: Additional arguments (ignored for Adagrad).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameters.\n",
    "      - state: Updated state dictionary.\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]\n",
    "    eps = hyperparams[\"eps\"]\n",
    "\n",
    "    if \"G\" not in state:\n",
    "        state[\"G\"] = torch.zeros_like(params)\n",
    "\n",
    "    # Accumulate squared gradients.\n",
    "    state[\"G\"] += grad**2\n",
    "\n",
    "    # Perform the Adagrad update.\n",
    "    new_params = params - lr * grad / (torch.sqrt(state[\"G\"]) + eps)\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lzeCmIFGwMN"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for Adagrad.\n",
    "adagrad_hyperparams = {\n",
    "    \"lr\": 0.01,   # Learning rate\n",
    "    \"eps\": 1e-8   # Small constant for numerical stability\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using Adagrad.\n",
    "run_all_optimizations(update_func=adagrad_update, hyperparams=adagrad_hyperparams, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Jz2gthSQ2cm"
   },
   "source": [
    "# Adagrad Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the Adagrad optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    adagrad_hyperparams = {\n",
    "        \"lr\": 0.01,   # Learning rate\n",
    "        \"eps\": 1e-8   # Small constant for numerical stability\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various learning rates and epsilon values to analyze how they affect the performance of Adagrad. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the learning rate and epsilon values you tested. Provide a clear list or table of these values.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different learning rates and epsilon values impact the convergence behavior of Adagrad?\n",
    "   - Were there any specific parameter combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested combinations cause the optimizer to get stuck in local minima?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of learning rate and epsilon achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying the learning rate and epsilon values. For instance, did a lower epsilon improve stability at the cost of slower convergence?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate and epsilon when using Adagrad in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the Adagrad optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-ZHeL0ELAkY"
   },
   "source": [
    "# RMSprop (Root Mean Square Propagation)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "RMSprop adapts the learning rate for each parameter by maintaining an exponentially decaying average of squared gradients. The update equations are:\n",
    "\n",
    "$$\n",
    "E[g^2]_t = \\beta \\, E[g^2]_{t-1} + (1 - \\beta) \\, \\left(\\nabla f(w_t)\\right)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\frac{\\eta}{\\sqrt{E[g^2]_t} + \\epsilon} \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\(w_t\\\\) is the parameter vector at iteration \\\\(t\\\\),\n",
    "- \\\\(E[g^2]_t\\\\) is the exponentially decaying average of squared gradients,\n",
    "- \\\\(\\eta\\\\) is the learning rate,\n",
    "- \\\\(\\beta\\\\) is the decay rate (typically around 0.9), and\n",
    "- \\\\(\\epsilon\\\\) is a small constant added for numerical stability.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "RMSprop is designed to overcome the aggressive decay of the learning rate seen in Adagrad by using an exponential decay factor \\\\(\\beta\\\\) to forget old gradients. This helps to maintain a more stable and adaptive learning rate during training. RMSprop works well in practice on non-stationary problems and deep networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2USzXZaeG5x8"
   },
   "outputs": [],
   "source": [
    "def rmsprop_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    RMSprop update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to parameters.\n",
    "      - state: Dictionary to store state (e.g., running average of squared gradients).\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "            \"lr\": learning rate,\n",
    "            \"beta\": decay rate, and\n",
    "            \"eps\": a small constant for numerical stability.\n",
    "      - **kwargs: Additional arguments (ignored for RMSprop).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameters.\n",
    "      - state: Updated state dictionary.\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]\n",
    "    beta = hyperparams[\"beta\"]\n",
    "    eps = hyperparams[\"eps\"]\n",
    "\n",
    "    if \"E\" not in state:\n",
    "        state[\"E\"] = torch.zeros_like(params)\n",
    "\n",
    "    # Update the running average of squared gradients.\n",
    "    state[\"E\"] = beta * state[\"E\"] + (1 - beta) * grad**2\n",
    "\n",
    "    # Compute the RMSprop update.\n",
    "    new_params = params - lr * grad / (torch.sqrt(state[\"E\"]) + eps)\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG1FUJg7G7AS"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for RMSprop.\n",
    "rmsprop_hyperparams = {\n",
    "    \"lr\": 0.001,    # Learning rate\n",
    "    \"beta\": 0.9,    # Decay rate\n",
    "    \"eps\": 1e-8     # Small constant for numerical stability\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using RMSprop.\n",
    "run_all_optimizations(update_func=rmsprop_update, hyperparams=rmsprop_hyperparams, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNV6AQIzRFlK"
   },
   "source": [
    "# RMSprop Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the RMSprop optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    rmsprop_hyperparams = {\n",
    "        \"lr\": 0.001,    # Learning rate\n",
    "        \"beta\": 0.9,    # Decay rate\n",
    "        \"eps\": 1e-8     # Small constant for numerical stability\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various learning rates, beta values, and epsilon values to analyze how they affect the performance of RMSprop. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the learning rate, beta, and epsilon values you tested. Provide a clear list or table of these values.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different combinations of learning rate, beta, and epsilon impact the convergence behavior of RMSprop?\n",
    "   - Were there any specific combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested combinations cause the optimizer to get stuck in local minima?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of parameters achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying these hyperparameters. For example, did a higher beta improve stability at the cost of slower adaptation?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate, beta, and epsilon when using RMSprop in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the RMSprop optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bx1B75YsHD5-"
   },
   "source": [
    "# Adam (Adaptive Moment Estimation)(10 Points)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "Adam computes two exponential moving averages of the gradients:\n",
    "\n",
    "- **First moment (mean):**\n",
    "\n",
    "$$\n",
    "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "- **Second moment (uncentered variance):**\n",
    "\n",
    "$$\n",
    "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\left(\\nabla f(w_t)\\right)^2\n",
    "$$\n",
    "\n",
    "Bias corrections are then applied:\n",
    "\n",
    "$$\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "$$\n",
    "\n",
    "Finally, the parameter update is given by:\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\, \\hat{m}_t\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\(w_t\\\\) is the parameter vector at iteration \\\\(t\\\\),\n",
    "- \\\\(\\eta\\\\) is the learning rate,\n",
    "- \\\\(\\beta_1\\\\) and \\\\(\\beta_2\\\\) are the exponential decay rates for the moment estimates, and\n",
    "- \\\\(\\epsilon\\\\) is a small constant to avoid division by zero.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Adam combines ideas from momentum and RMSprop. By maintaining an exponentially decaying average of past gradients (first moment) and past squared gradients (second moment) along with bias correction, Adam adapts the learning rate for each parameter. This makes it especially suitable for problems with noisy or sparse gradients, as it works well \"out of the box\" with minimal tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1ygVwm-G8Gc"
   },
   "outputs": [],
   "source": [
    "def adam_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    Adam update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to params.\n",
    "      - state: Dictionary to store moving averages for first and second moments.\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "            \"lr\": learning rate,\n",
    "            \"beta1\": decay rate for the first moment,\n",
    "            \"beta2\": decay rate for the second moment,\n",
    "            \"eps\": a small constant for numerical stability.\n",
    "      - **kwargs: Additional arguments (ignored for Adam).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameter values.\n",
    "      - state: Updated state dictionary.\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]\n",
    "    beta1 = hyperparams[\"beta1\"]\n",
    "    beta2 = hyperparams[\"beta2\"]\n",
    "    eps = hyperparams[\"eps\"]\n",
    "\n",
    "    if \"m\" not in state:\n",
    "        # TODO: Initialize first moment (m), second moment (v), and timestep (t)\n",
    "        state[\"m\"] = None  # Replace with correct initialization\n",
    "        state[\"v\"] = None  # Replace with correct initialization\n",
    "        state[\"t\"] = None  # Replace with correct initialization\n",
    "\n",
    "    # TODO: Update timestep\n",
    "    state[\"t\"] = None  # Replace with actual update\n",
    "\n",
    "    # TODO: Compute biased first moment estimate (m) and second moment estimate (v)\n",
    "    state[\"m\"] = None  # Replace with first moment update\n",
    "    state[\"v\"] = None  # Replace with second moment update\n",
    "\n",
    "    # TODO: Compute bias-corrected first moment estimate (m_hat) and second moment estimate (v_hat)\n",
    "    m_hat = None  # Replace with bias correction\n",
    "    v_hat = None  # Replace with bias correction\n",
    "\n",
    "    # TODO: Update parameters using Adam's rule\n",
    "    new_params = None  # Replace with correct parameter update\n",
    "\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLTL4r2tHFj9"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for Adam.\n",
    "adam_hyperparams = {\n",
    "    \"lr\": 0.001,      # Learning rate\n",
    "    \"beta1\": 0.9,     # Decay rate for first moment\n",
    "    \"beta2\": 0.999,   # Decay rate for second moment\n",
    "    \"eps\": 1e-8       # Smoothing constant\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using Adam.\n",
    "run_all_optimizations(update_func=adam_update, hyperparams=adam_hyperparams, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBOnUPf5RTpR"
   },
   "source": [
    "# Adam Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the Adam optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    adam_hyperparams = {\n",
    "        \"lr\": 0.001,      # Learning rate\n",
    "        \"beta1\": 0.9,     # Decay rate for first moment\n",
    "        \"beta2\": 0.999,   # Decay rate for second moment\n",
    "        \"eps\": 1e-8       # Smoothing constant\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various combinations of the learning rate, beta1, beta2, and epsilon values to analyze how they affect the performance of Adam. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the values you tested for learning rate, beta1, beta2, and epsilon. Provide a clear list or table of these parameter combinations.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different parameter combinations impact the convergence behavior of Adam?\n",
    "   - Were there any specific combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested parameter combinations cause the optimizer to get stuck in local minima?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of parameters achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying these hyperparameters. For example, did a lower epsilon or higher beta values improve stability at the cost of slower convergence?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate, beta1, beta2, and epsilon when using Adam in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the Adam optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2y7c6J7rHi1Q"
   },
   "source": [
    "# Newton’s Method(5 Points)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "Newton’s method uses second-order information (the Hessian) to update the parameters. The update rule is given by:\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - H(w_t)^{-1} \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\( w_t \\\\) is the parameter vector at iteration \\\\( t \\\\),\n",
    "- \\\\( \\nabla f(w_t) \\\\) is the gradient of the loss function at \\\\( w_t \\\\), and\n",
    "- \\\\( H(w_t) \\\\) is the Hessian matrix (i.e., the matrix of second derivatives) evaluated at \\\\( w_t \\\\).\n",
    "\n",
    "For numerical stability (and to handle cases when the Hessian is nearly singular), a small constant \\\\( \\epsilon \\\\) is added to the diagonal of the Hessian:\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\left( H(w_t) + \\epsilon I \\right)^{-1} \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Newton’s method can converge very rapidly (quadratically) when the loss function is well-behaved and when you are close to the optimum. However, computing the full Hessian (and its inverse) can be computationally expensive for high-dimensional problems. Because of these challenges, Newton’s method (or its quasi-Newton variants like L-BFGS) is typically used for smaller models or as part of a hybrid optimization strategy.\n",
    "\n",
    "*Note:* In our implementation, we assume the loss function is defined using PyTorch, the parameters are a torch tensor of shape \\\\( (n,) \\\\) for 1D functions or \\\\( (2,) \\\\) for 2D functions, and the Hessian is computed via PyTorch’s automatic differentiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4p-AIjsHG32"
   },
   "outputs": [],
   "source": [
    "def newton_update(params, grad, state, hyperparams, hessian):\n",
    "    \"\"\"\n",
    "    Newton's Method update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor, shape (n,) for 1D or (2,) for 2D).\n",
    "      - grad: Gradient of the loss with respect to params (torch tensor).\n",
    "      - state: Dictionary to store state (not used in basic Newton's method).\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "            \"eps\": A small constant for numerical stability.\n",
    "      - hessian: Hessian matrix of the loss function (torch tensor of shape (n, n)).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameter values.\n",
    "      - state: Unchanged state dictionary.\n",
    "    \"\"\"\n",
    "    eps = hyperparams[\"eps\"]\n",
    "\n",
    "    # TODO: Create an identity matrix of the same size as params\n",
    "    I = None  # Replace with correct initialization\n",
    "\n",
    "    # TODO: Regularize the Hessian for numerical stability\n",
    "    H_reg = None  # Replace with correct computation\n",
    "\n",
    "    # TODO: Compute the inverse of the regularized Hessian\n",
    "    H_inv = None  # Replace with correct computation\n",
    "\n",
    "    # TODO: Compute the Newton update step: new_params = params - H_inv @ grad\n",
    "    new_params = None  # Replace with correct update formula\n",
    "\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRi7NpomHnW7"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for Newton's method.\n",
    "newton_hyperparams = {\n",
    "    \"eps\": 1e-4   # Small constant for numerical stability\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using Newton's method.\n",
    "# Note: Newton's method is a second-order method, so our general optimize function should be called with second_order=True.\n",
    "run_all_optimizations(update_func=newton_update, hyperparams=newton_hyperparams, epochs=100, second_order=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRoCPZNuRqWb"
   },
   "source": [
    "# Newton's Method Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For Newton's Method, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    newton_hyperparams = {\n",
    "        \"eps\": 1e-4   # Small constant for numerical stability\n",
    "    }\n",
    "\n",
    "In this section, you are required to test different values for the epsilon parameter to analyze its effect on the performance of Newton's Method. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the epsilon values you tested. Provide a clear list or table of these values.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different epsilon values impact the convergence behavior of Newton's Method?\n",
    "   - Were there any specific epsilon values that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested epsilon values cause the optimizer to get stuck in local minima or result in numerical instability?\n",
    "\n",
    "3. **Optimal Parameter:**\n",
    "   - Which epsilon value, among those tested, achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider this epsilon value optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying epsilon. For example, did a smaller epsilon provide more precise curvature estimates at the cost of slower convergence?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the epsilon parameter when using Newton's Method in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all epsilon values tested. Your analysis should clearly illustrate how the choice of this hyperparameter influences the performance of Newton's Method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyaCL1hSKpec"
   },
   "source": [
    "# L-BFGS (Limited-memory BFGS)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "L-BFGS is a quasi-Newton method that approximates the inverse Hessian matrix using a limited history of parameter and gradient differences. It avoids storing the full Hessian, making it memory efficient for large-scale problems.\n",
    "\n",
    "Suppose at iteration \\\\(t\\\\) we have stored \\\\(m\\\\) pairs \\\\((s_i, y_i)\\\\) for \\\\(i = t-m, \\ldots, t-1\\\\), where\n",
    "\n",
    "$$\n",
    "s_i = w_{i+1} - w_i \\quad \\text{and} \\quad y_i = \\nabla f(w_{i+1}) - \\nabla f(w_i).\n",
    "$$\n",
    "\n",
    "The two-loop recursion for computing the approximate inverse Hessian times the gradient \\\\(q = \\nabla f(w_t)\\\\) is as follows:\n",
    "\n",
    "1. **First Loop (backward pass):**\n",
    "\n",
    "   For \\\\(i = t-1, t-2, \\ldots, t-m\\\\):\n",
    "\n",
    "   $$\n",
    "   \\rho_i = \\frac{1}{y_i^T s_i} \\quad,\\quad \\alpha_i = \\rho_i \\, s_i^T q\n",
    "   $$\n",
    "\n",
    "   Update:\n",
    "\n",
    "   $$\n",
    "   q \\leftarrow q - \\alpha_i \\, y_i\n",
    "   $$\n",
    "\n",
    "2. **Scaling the Initial Hessian:**\n",
    "\n",
    "   Use an initial Hessian approximation:\n",
    "\n",
    "   $$\n",
    "   H_0 = \\gamma I \\quad \\text{with} \\quad \\gamma = \\frac{s_{t-1}^T y_{t-1}}{y_{t-1}^T y_{t-1}}\n",
    "   $$\n",
    "\n",
    "   Set:\n",
    "\n",
    "   $$\n",
    "   r = H_0 q\n",
    "   $$\n",
    "\n",
    "3. **Second Loop (forward pass):**\n",
    "\n",
    "   For \\\\(i = t-m, \\ldots, t-1\\\\):\n",
    "\n",
    "   $$\n",
    "   \\beta_i = \\rho_i \\, y_i^T r\n",
    "   $$\n",
    "\n",
    "   Update:\n",
    "\n",
    "   $$\n",
    "   r \\leftarrow r + s_i (\\alpha_i - \\beta_i)\n",
    "   $$\n",
    "\n",
    "The parameter update is then:\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - r.\n",
    "$$\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "L-BFGS efficiently approximates the Newton direction without computing or storing the full Hessian matrix. By keeping a limited memory of recent changes in parameters and gradients, it builds a useful approximation of the inverse Hessian that can lead to fast convergence on large-scale problems. The hyperparameter \\\\(m\\\\) controls the memory size (i.e., how many past updates are retained), and the initial scaling factor \\\\(\\gamma\\\\) helps initialize the inverse Hessian approximation.\n",
    "\n",
    "*Note:* In our implementation, we maintain lists of differences \\\\(s_i\\\\) and \\\\(y_i\\\\), and use the two-loop recursion to compute the search direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObUW2ZHjH0R1"
   },
   "outputs": [],
   "source": [
    "def lbfgs_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    L-BFGS update function (simplified version).\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to params (torch tensor).\n",
    "      - state: Dictionary to store state.\n",
    "          Expected keys:\n",
    "            \"S\": list of previous parameter differences.\n",
    "            \"Y\": list of previous gradient differences.\n",
    "            \"prev_params\": previous parameters (torch tensor).\n",
    "            \"prev_grad\": previous gradient (torch tensor).\n",
    "      - hyperparams: Dictionary of hyperparameters.\n",
    "          Must contain:\n",
    "            \"lr\": initial learning rate scaling factor,\n",
    "            \"m\": memory size (maximum number of corrections to store).\n",
    "      - **kwargs: Additional arguments (ignored for L-BFGS).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameter values.\n",
    "      - state: Updated state dictionary.\n",
    "    \"\"\"\n",
    "    lr = hyperparams[\"lr\"]\n",
    "    m_memory = hyperparams[\"m\"]\n",
    "\n",
    "    # If no previous state exists, do a simple gradient descent step.\n",
    "    if \"prev_params\" not in state:\n",
    "        new_params = params - lr * grad\n",
    "        state[\"prev_params\"] = params.clone().detach()\n",
    "        state[\"prev_grad\"] = grad.clone().detach()\n",
    "        state[\"S\"] = []\n",
    "        state[\"Y\"] = []\n",
    "        return new_params, state\n",
    "\n",
    "    # Compute parameter difference s and gradient difference y.\n",
    "    s = params - state[\"prev_params\"]\n",
    "    y = grad - state[\"prev_grad\"]\n",
    "\n",
    "    # Update history lists.\n",
    "    if len(state[\"S\"]) >= m_memory:\n",
    "        state[\"S\"].pop(0)\n",
    "        state[\"Y\"].pop(0)\n",
    "    state[\"S\"].append(s.clone().detach())\n",
    "    state[\"Y\"].append(y.clone().detach())\n",
    "\n",
    "    # Update previous parameters and gradient.\n",
    "    state[\"prev_params\"] = params.clone().detach()\n",
    "    state[\"prev_grad\"] = grad.clone().detach()\n",
    "\n",
    "    # Two-loop recursion.\n",
    "    q = grad.clone().detach()\n",
    "    alpha = []\n",
    "    # Loop from the most recent history to the oldest.\n",
    "    for s_i, y_i in zip(reversed(state[\"S\"]), reversed(state[\"Y\"])):\n",
    "        rho_i = 1.0 / (torch.dot(y_i.view(-1), s_i.view(-1)) + 1e-10)\n",
    "        a_i = rho_i * torch.dot(s_i.view(-1), q.view(-1))\n",
    "        alpha.append(a_i)\n",
    "        q = q - a_i * y_i\n",
    "\n",
    "    # Scaling for initial Hessian approximation.\n",
    "    if len(state[\"Y\"]) > 0:\n",
    "        last_y = state[\"Y\"][-1]\n",
    "        last_s = state[\"S\"][-1]\n",
    "        gamma = torch.dot(last_y.view(-1), last_s.view(-1)) / (torch.dot(last_y.view(-1), last_y.view(-1)) + 1e-10)\n",
    "    else:\n",
    "        gamma = 1.0\n",
    "\n",
    "    r = gamma * q\n",
    "    # Forward loop: from oldest to newest.\n",
    "    for s_i, y_i, a_i in zip(state[\"S\"], state[\"Y\"], reversed(alpha)):\n",
    "        rho_i = 1.0 / (torch.dot(y_i.view(-1), s_i.view(-1)) + 1e-10)\n",
    "        beta = rho_i * torch.dot(y_i.view(-1), r.view(-1))\n",
    "        r = r + s_i * (a_i - beta)\n",
    "\n",
    "    # Update parameters: move in the direction r.\n",
    "    new_params = params - r\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "No4LuEnjKsOY"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for L-BFGS.\n",
    "lbfgs_hyperparams = {\n",
    "    \"lr\": 0.01,   # initial learning rate scaling factor\n",
    "    \"m\": 10       # memory size (maximum corrections to store)\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using L-BFGS.\n",
    "run_all_optimizations(update_func=lbfgs_update, hyperparams=lbfgs_hyperparams, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1iVUH2tR0Rc"
   },
   "source": [
    "# L-BFGS Hyperparameter Analysis\n",
    "\n",
    "For the L-BFGS optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    lbfgs_hyperparams = {\n",
    "        \"lr\": 0.01,   # initial learning rate scaling factor\n",
    "        \"m\": 10       # memory size (maximum corrections to store)\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various values for the learning rate and memory size to analyze how they affect the performance of L-BFGS. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the learning rate and memory size (m) values you tested. Provide a clear list or table of these parameter combinations.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different combinations of learning rate and memory size impact the convergence behavior of L-BFGS?\n",
    "   - Were there any specific parameter combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested combinations cause the optimizer to get trapped in local minima or exhibit other issues?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of learning rate and memory size achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying these hyperparameters. For example, did a higher memory size improve convergence at the cost of increased computation time?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate and memory size when using L-BFGS in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the L-BFGS optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYPm-EFdK1YX"
   },
   "source": [
    "# Nadam (Nesterov-accelerated Adam)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "Nadam combines the ideas of Adam and Nesterov momentum. Its update equations are as follows:\n",
    "\n",
    "1. **First Moment Update:**\n",
    "\n",
    "$$\n",
    "m_t = \\beta_1 \\, m_{t-1} + (1 - \\beta_1) \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "2. **Second Moment Update:**\n",
    "\n",
    "$$\n",
    "v_t = \\beta_2 \\, v_{t-1} + (1 - \\beta_2) \\, \\left(\\nabla f(w_t)\\right)^2\n",
    "$$\n",
    "\n",
    "3. **Bias Correction:**\n",
    "\n",
    "$$\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "$$\n",
    "\n",
    "4. **Nesterov Lookahead Term:**\n",
    "\n",
    "Instead of using \\\\(\\hat{m}_t\\\\) directly, Nadam uses a combination of the previous moment and the current gradient:\n",
    "\n",
    "$$\n",
    "m_{\\text{bar}} = \\frac{\\beta_1 \\, m_{t-1} + (1-\\beta_1) \\, \\nabla f(w_t)}{1-\\beta_1^t}\n",
    "$$\n",
    "\n",
    "5. **Parameter Update:**\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\, m_{\\text{bar}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\(w_t\\\\) is the parameter vector at iteration \\\\(t\\\\),\n",
    "- \\\\(\\eta\\\\) is the learning rate,\n",
    "- \\\\(\\beta_1\\\\) and \\\\(\\beta_2\\\\) are the decay rates for the first and second moments, and\n",
    "- \\\\(\\epsilon\\\\) is a small constant for numerical stability.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Nadam (Nesterov-accelerated Adam) improves upon Adam by incorporating Nesterov’s accelerated gradient. Instead of updating with just the biased-corrected first moment \\\\(\\hat{m}_t\\\\), Nadam uses a lookahead estimate \\\\(m_{\\text{bar}}\\\\) that blends the previous momentum with the current gradient. This “lookahead” helps the optimizer to better anticipate the direction of the parameter update, often leading to faster convergence in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exqNW0xsK3T0"
   },
   "outputs": [],
   "source": [
    "def nadam_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    Nadam update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to params (torch tensor).\n",
    "      - state: Dictionary to store moving averages for the first and second moments.\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "            \"lr\": learning rate,\n",
    "            \"beta1\": decay rate for the first moment,\n",
    "            \"beta2\": decay rate for the second moment,\n",
    "            \"eps\": small constant for numerical stability.\n",
    "      - **kwargs: Additional arguments (ignored for Nadam).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameter values.\n",
    "      - state: Updated state dictionary.\n",
    "    \"\"\"\n",
    "    lr    = hyperparams[\"lr\"]\n",
    "    beta1 = hyperparams[\"beta1\"]\n",
    "    beta2 = hyperparams[\"beta2\"]\n",
    "    eps   = hyperparams[\"eps\"]\n",
    "\n",
    "    if \"m\" not in state:\n",
    "        state[\"m\"] = torch.zeros_like(params)\n",
    "        state[\"v\"] = torch.zeros_like(params)\n",
    "        state[\"t\"] = 0\n",
    "\n",
    "    # Save the previous first moment (for the lookahead term).\n",
    "    m_prev = state[\"m\"].clone()\n",
    "    state[\"t\"] += 1\n",
    "\n",
    "    # Update first moment.\n",
    "    state[\"m\"] = beta1 * state[\"m\"] + (1 - beta1) * grad\n",
    "    # Update second moment.\n",
    "    state[\"v\"] = beta2 * state[\"v\"] + (1 - beta2) * grad**2\n",
    "\n",
    "    # Bias-corrected moments.\n",
    "    m_hat = state[\"m\"] / (1 - beta1 ** state[\"t\"])\n",
    "    v_hat = state[\"v\"] / (1 - beta2 ** state[\"t\"])\n",
    "\n",
    "    # Compute the lookahead (Nesterov) term:\n",
    "    m_bar = (beta1 * m_prev + (1 - beta1) * grad) / (1 - beta1 ** state[\"t\"])\n",
    "\n",
    "    # Update parameters.\n",
    "    new_params = params - lr * m_bar / (torch.sqrt(v_hat) + eps)\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AeitYOdKs_t"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for Nadam.\n",
    "nadam_hyperparams = {\n",
    "    \"lr\": 0.001,      # Learning rate\n",
    "    \"beta1\": 0.9,     # Decay rate for first moment\n",
    "    \"beta2\": 0.999,   # Decay rate for second moment\n",
    "    \"eps\": 1e-8       # Small constant for numerical stability\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using Nadam.\n",
    "run_all_optimizations(update_func=nadam_update, hyperparams=nadam_hyperparams, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQEZwb6UR-_I"
   },
   "source": [
    "# Nadam Hyperparameter Analysis(5 Points)\n",
    "\n",
    "For the Nadam optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    nadam_hyperparams = {\n",
    "        \"lr\": 0.001,      # Learning rate\n",
    "        \"beta1\": 0.9,     # Decay rate for first moment\n",
    "        \"beta2\": 0.999,   # Decay rate for second moment\n",
    "        \"eps\": 1e-8       # Small constant for numerical stability\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various combinations of the learning rate, beta1, beta2, and epsilon values to analyze how they affect the performance of Nadam. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the values you tested for the learning rate, beta1, beta2, and epsilon. Provide a clear list or table of these parameter combinations.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different parameter combinations impact the convergence behavior of Nadam?\n",
    "   - Were there any specific combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested parameter combinations cause the optimizer to get trapped in local minima or exhibit other issues?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of parameters achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying these hyperparameters. For example, did lower epsilon or higher beta values improve stability at the cost of slower convergence?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the learning rate, beta1, beta2, and epsilon when using Nadam in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the Nadam optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHZvVop1LB3W"
   },
   "source": [
    "# AdaDelta\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "\n",
    "AdaDelta adaptively adjusts the learning rate by using an exponentially decaying average of past squared gradients and squared updates. The update rules are as follows:\n",
    "\n",
    "1. **Accumulate Squared Gradients:**\n",
    "\n",
    "$$\n",
    "E[g^2]_t = \\rho \\, E[g^2]_{t-1} + (1-\\rho) \\, \\left(\\nabla f(w_t)\\right)^2\n",
    "$$\n",
    "\n",
    "2. **Compute the Parameter Update:**\n",
    "\n",
    "$$\n",
    "\\Delta w_t = - \\frac{\\sqrt{E[\\Delta w^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} \\, \\nabla f(w_t)\n",
    "$$\n",
    "\n",
    "3. **Update the Parameters:**\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t + \\Delta w_t\n",
    "$$\n",
    "\n",
    "4. **Accumulate Squared Updates:**\n",
    "\n",
    "$$\n",
    "E[\\Delta w^2]_t = \\rho \\, E[\\Delta w^2]_{t-1} + (1-\\rho) \\, \\left(\\Delta w_t\\right)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\\\( \\rho \\\\) is the decay rate (typically around 0.95 or 0.9),\n",
    "- \\\\( \\epsilon \\\\) is a small constant for numerical stability,\n",
    "- \\\\( w_t \\\\) is the parameter vector at iteration \\\\( t \\\\),\n",
    "- \\\\( \\nabla f(w_t) \\\\) is the gradient at \\\\( w_t \\\\), and\n",
    "- \\\\( E[g^2]_t \\\\) and \\\\( E[\\Delta w^2]_t \\\\) are the exponentially decaying averages of squared gradients and updates, respectively.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "AdaDelta is designed to overcome the aggressive learning rate decay problem of Adagrad by limiting the window of accumulated past gradients using an exponential decay. It does not require an explicit initial learning rate (though you may still set one if desired) and adapts the step size based on the history of gradients and updates. This makes AdaDelta particularly useful for problems where the optimal learning rate changes over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORBNSW6oK45O"
   },
   "outputs": [],
   "source": [
    "def adadelta_update(params, grad, state, hyperparams, **kwargs):\n",
    "    \"\"\"\n",
    "    AdaDelta update function.\n",
    "\n",
    "    Parameters:\n",
    "      - params: Current parameter values (torch tensor).\n",
    "      - grad: Gradient of the loss with respect to params (torch tensor).\n",
    "      - state: Dictionary to store state variables.\n",
    "          Expected keys:\n",
    "            \"Eg2\": Exponential moving average of squared gradients.\n",
    "            \"Edw2\": Exponential moving average of squared updates.\n",
    "      - hyperparams: Dictionary of hyperparameters. Must contain:\n",
    "            \"rho\": Decay rate (e.g., 0.95),\n",
    "            \"eps\": A small constant for numerical stability.\n",
    "      - **kwargs: Additional arguments (ignored for AdaDelta).\n",
    "\n",
    "    Returns:\n",
    "      - new_params: Updated parameter values.\n",
    "      - state: Updated state dictionary.\n",
    "    \"\"\"\n",
    "    rho = hyperparams[\"rho\"]\n",
    "    eps = hyperparams[\"eps\"]\n",
    "\n",
    "    # Initialize state if not present.\n",
    "    if \"Eg2\" not in state:\n",
    "        state[\"Eg2\"] = torch.zeros_like(params)\n",
    "    if \"Edw2\" not in state:\n",
    "        state[\"Edw2\"] = torch.zeros_like(params)\n",
    "\n",
    "    # Update the exponential moving average of squared gradients.\n",
    "    state[\"Eg2\"] = rho * state[\"Eg2\"] + (1 - rho) * grad**2\n",
    "\n",
    "    # Compute the update:\n",
    "    # Note: Classic AdaDelta uses an effective learning rate of 1.\n",
    "    update = - (torch.sqrt(state[\"Edw2\"] + eps) / torch.sqrt(state[\"Eg2\"] + eps)) * grad\n",
    "\n",
    "    # Update parameters.\n",
    "    new_params = params + update\n",
    "\n",
    "    # Update the exponential moving average of squared updates.\n",
    "    state[\"Edw2\"] = rho * state[\"Edw2\"] + (1 - rho) * update**2\n",
    "\n",
    "    return new_params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtC5EThVLDvq"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for AdaDelta.\n",
    "adadelta_hyperparams = {\n",
    "    \"rho\": 0.95,    # Decay rate\n",
    "    \"eps\": 1e-6     # Small constant for numerical stability\n",
    "}\n",
    "\n",
    "# Run optimizations for all benchmark functions using AdaDelta.\n",
    "run_all_optimizations(update_func=adadelta_update, hyperparams=adadelta_hyperparams, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvX1PCYJSraw"
   },
   "source": [
    "# Adadelta Hyperparameter Analysis\n",
    "\n",
    "For the Adadelta optimizer, we have defined the initial hyperparameters as follows:\n",
    "\n",
    "    adadelta_hyperparams = {\n",
    "        \"rho\": 0.95,    # Decay rate\n",
    "        \"eps\": 1e-6     # Small constant for numerical stability\n",
    "    }\n",
    "\n",
    "In this section, you are required to test various values for the decay rate (rho) and epsilon to analyze how they affect the performance of Adadelta. Please answer the following questions based on your experiments:\n",
    "\n",
    "1. **Parameter Variation:**\n",
    "   - List all the values you tested for rho and epsilon. Provide a clear list or table of these parameter combinations.\n",
    "\n",
    "2. **Performance Analysis:**\n",
    "   - How did different values of rho and epsilon impact the convergence behavior of Adadelta?\n",
    "   - Were there any specific parameter combinations that resulted in unstable behavior, overshooting, or slow convergence?\n",
    "   - Did any of the tested combinations cause the optimizer to get stuck in local minima or exhibit other issues?\n",
    "\n",
    "3. **Optimal Parameters:**\n",
    "   - Which combination of rho and epsilon achieved the best balance between convergence speed and stability?\n",
    "   - Explain why you consider these parameters optimal based on your observations.\n",
    "\n",
    "4. **Trade-offs and Observations:**\n",
    "   - Discuss any trade-offs you noticed when varying rho and epsilon. For example, did a higher rho improve convergence stability at the cost of slower updates?\n",
    "   - Describe any patterns or trends that emerged from your experiments.\n",
    "\n",
    "5. **Recommendations:**\n",
    "   - Based on your experimental results, what recommendations would you give for selecting the decay rate and epsilon when using Adadelta in similar optimization tasks?\n",
    "\n",
    "Ensure your report includes detailed observations, a comparative analysis, and a summary of all parameter combinations tested. Your analysis should clearly illustrate how the choice of these hyperparameters influences the performance of the Adadelta optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4VEzCEDS7kE"
   },
   "source": [
    "# Final Section\n",
    "\n",
    "I hope you enjoyed implementing these concepts. For the final submission, you are required to integrate your explanations regarding the algorithms discussed above. You simply need to elaborate on the points provided here.\n",
    "\n",
    "Best of luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKcB6MW0TDy3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
