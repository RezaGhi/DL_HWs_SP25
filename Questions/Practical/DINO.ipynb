{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc7j5Wdv1BKL"
      },
      "source": [
        "# **Zero-Shot Object Detection with Grounding DINO**\n",
        "\n",
        "In this homework, we explore DINO and Grounding DINO, two powerful vision models that give us valuable insights about **self-supervised learning** and **grounding tasks**.\n",
        "\n",
        "We begin by working with DINO, a self-supervised vision transformer that learns to understand image structure without any labeled data. In this section, you’ll visualize attention maps produced by DINO to see where the model focuses when interpreting an image.\n",
        "\n",
        "Next, we move on to Grounding DINO, an object detector capable of performing zero-shot detection, detecting and localizing objects based on free-form text prompts like \"a person with a hat\" or \"a red car.\" This allows you to detect arbitrary objects without any task-specific training.\n",
        "\n",
        "### What You'll Learn\n",
        "- How to extract and visualize attention maps from DINO to interpret model focus.\n",
        "- How to load and use Grounding DINO for zero-shot object detection.\n",
        "- How to detect objects in images using textual prompts — without any task-specific fine-tuning.\n",
        "- How to draw bounding boxes and confidence scores on detected objects to visualize the results.\n",
        "- The strengths and limitations of zero-shot object detection in real-world applications.\n",
        "\n",
        "\n",
        "\n",
        "We’ll walk through an end-to-end example, starting from setup and preprocessing, all the way to performing detection and visualizing the results.\n",
        "Let’s dive in and explore how vision and language can come together for powerful object detection, without the need for fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Part 1 : Visualizing Attention Maps in DINO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "In this section, we explore **DINO** (Self-Distillation with No Labels), a self-supervised learning framework designed for Vision Transformers (ViTs). Our goal is to understand how DINO works and visualize the attention maps it produces to gain insights into how the model interprets images.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Overview of DINO**\n",
        "\n",
        "DINO employs a **self-distillation** approach using a student–teacher architecture. Both the student and teacher networks share the same backbone (typically a Vision Transformer), and the learning objective is to produce similar feature representations for different augmented views of the same image (Self-Supervised Learning).\n",
        "\n",
        "- The **student** network is trained via gradient descent.\n",
        "- The **teacher** is updated as an **exponential moving average (EMA)** of the student parameters, ensuring stability over time.\n",
        "\n",
        "This setup encourages the model to learn consistent and robust representations.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Why DINO is Effective**\n",
        "\n",
        "One of the most intriguing aspects of DINO is that despite being trained without labels, it learns to focus on semantically meaningful regions in an image. This behavior emerges naturally from the **self-attention** mechanism in Vision Transformers, where each patch in the image can attend to all other patches.\n",
        "\n",
        "By examining the attention weights from the `[CLS]` token to the image patches, we can visualize what parts of the image the model considers important. These attention maps often highlight entire objects or object parts, revealing that DINO captures object-level semantics.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. DINO Training Setup**\n",
        "\n",
        "In the illustration below, the training process is shown for a single pair of augmented views $(x_1, x_2)$ of the same image:\n",
        "\n",
        "- Both views are passed through the student and teacher networks.\n",
        "- The teacher’s output is centered using a batch-wise mean to stabilize the learning dynamics.\n",
        "- Each output is projected into a $K$-dimensional feature space and normalized using a temperature-scaled softmax.\n",
        "- The similarity between student and teacher outputs is measured using cross-entropy.\n",
        "- A **stop-gradient** operator is applied to the teacher output to prevent gradient flow through the teacher network.\n",
        "- The teacher parameters are updated via EMA of the student parameters.\n",
        "\n",
        "This training pipeline helps the model learn invariant features across different views, and leads to highly structured attention behavior.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Further Reading**\n",
        "\n",
        "For a further understanding of DINO's methodology, refer to the original paper:  \n",
        "📄 [DINO: Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)\n",
        "\n",
        "---\n",
        "\n",
        "In the following cells, we will visualize DINO's attention maps using pretrained weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZxBS2xS3e3m"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Pretrained DINO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JApTQlwoEzdo"
      },
      "source": [
        "First, we clone the DINO repository from Facebook Research to access the pretrained DINO model. This repository contains the necessary code and model implementations for extracting attention maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFCoYqBR0rVG",
        "outputId": "974074e3-3294-4c01-cbab-d789eda99870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'dino'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Total 175 (delta 0), reused 0 (delta 0), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (175/175), 24.47 MiB | 15.34 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/dino.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to navigate to the repository folder to access model files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRzeunZG0r9V",
        "outputId": "a70949d2-ce1d-468e-ff3b-c1f5d05c1a68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/dino\n"
          ]
        }
      ],
      "source": [
        "cd dino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMSEsxQuBwkr"
      },
      "source": [
        "### Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we need ton import necessary libraries such as `PIL`, `cv2`, and `skimage` for image processing and `utils` and `vision_trasnformers` for DINO-specific utilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qr0lV1r0yZF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import shutil\n",
        "import skimage.io\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms as pth_transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import utils\n",
        "import vision_transformer as vits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5aofJiFBS9"
      },
      "source": [
        "### Attention Map Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3q5O9P0FGjl"
      },
      "source": [
        "We define a function `dinoAttention` to extract and visualize attention maps from the DINO model for a given input image. At first, the base model architecture needs to be determined alongside the patch size in which the images are going to be processed. If there's access to the pretrained weights locally, we will need to load them using the weights file. If not, the pretrained weights should be loaded from online resources. Attention maps are normalized, thresholded, and resized to match the original image dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMA-bnld0zYW"
      },
      "outputs": [],
      "source": [
        "def dinoAttention(image_path = None):\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # Params\n",
        "    # TODO: Select suitable values for the parameters\n",
        "    arch = ...\n",
        "    patch_size = ...\n",
        "\n",
        "    pretrained_weights = ...\n",
        "    checkpoint_key = 'student'\n",
        "    threshold = ...\n",
        "\n",
        "    # build model\n",
        "    # TODO: Load and initialize the model using patch_size and arch\n",
        "    model = ...\n",
        "\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    # TODO: Load the pretrained weights and state dictionary for the model\n",
        "\n",
        "    # open image\n",
        "    if image_path is None:\n",
        "        print(\"Using default image since no path provided\")\n",
        "        response = requests.get(\"https://dl.fbaipublicfiles.com/dino/img.png\")\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img = img.convert('RGB')\n",
        "    elif os.path.isfile(image_path):\n",
        "        with open(image_path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert('RGB')\n",
        "    else:\n",
        "        print(f\"Provided image path {image_path} is invalid.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # transform image\n",
        "    transform = pth_transforms.Compose([\n",
        "        pth_transforms.ToTensor(),\n",
        "        pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "    img = transform(img)\n",
        "\n",
        "\n",
        "\n",
        "    # make the image divisible by the patch size\n",
        "    w, h = img.shape[1] - img.shape[1] % patch_size, img.shape[2] - img.shape[2] % patch_size\n",
        "    img = img[:, :w, :h].unsqueeze(0)\n",
        "\n",
        "    # TODO: Get attention maps\n",
        "    attentions = ...\n",
        "    nh = attentions.shape[1]\n",
        "\n",
        "    # TODO: keep only a certain percentage of the mass\n",
        "\n",
        "\n",
        "    # TODO: reshape and interpolate attention maps\n",
        "\n",
        "    # normalize and visualize\n",
        "    normalized_attentions = np.array([min_max_normalize(attentions[i]) for i in range(attentions.shape[0])])\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(1, nh + 1, figsize=(5*(nh + 1), 5))\n",
        "\n",
        "    # Show original image\n",
        "    original_img = img.squeeze().permute(1, 2, 0).numpy()\n",
        "    original_img = (original_img - original_img.min()) / (original_img.max() - original_img.min())\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Show each attention head\n",
        "    for i in range(nh):\n",
        "        axes[i+1].imshow(normalized_attentions[i], cmap='inferno')\n",
        "        axes[i+1].set_title(f'Attention Head {i+1}')\n",
        "        axes[i+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return normalized_attentions\n",
        "\n",
        "def min_max_normalize(x):\n",
        "    return (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By calling the `dinoAttention` function with our preferred image as input, we can visualize the attention maps in different attention heads for the image. The original image and attention maps for each head are plotted side by side.\n",
        "Note that you don't need to implement visualization functions but do so if you feel the need to. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6Eb6b2v14Qc"
      },
      "outputs": [],
      "source": [
        "attention_maps = dinoAttention(\"content/cat.JPEG\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Question :** Based on your observations after showing the attention maps, what information can we gain from each attention map for each head represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD7GFDiKGCO4"
      },
      "source": [
        "## **Part 2: Grounding DINO for Text-Guided Object Detection**\n",
        "\n",
        "In the previous section, we explored how DINO attends to different regions in an image using self- and cross-attention mechanisms. In this section, we examine one of the key applications of DINO: **text-guided object detection**. This task involves detecting and localizing objects in an image based on natural language input, such as \"a red backpack\" or \"a person riding a horse\", without being restricted to a predefined set of object categories.\n",
        "\n",
        "To achieve this, we use **Grounding DINO**, a recent extension of DINO that integrates language understanding into the object detection pipeline. Grounding DINO enables the model to interpret free-form textual descriptions and identify corresponding visual regions, a process known as **grounding**.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What is Grounding?**\n",
        "\n",
        "In the context of computer vision, *grounding* refers to the task of linking natural language expressions to specific objects or regions within an image. Unlike traditional object detection models, which are typically trained to recognize a fixed list of object categories (e.g., the 80 categories in COCO), grounding models can respond to open-ended textual queries.\n",
        "\n",
        "**Examples of grounding queries:**\n",
        "- “Locate the brown dog lying on the grass.”\n",
        "- “Find the traffic light near the white car.”\n",
        "\n",
        "Grounding is particularly valuable in applications such as:\n",
        "- Human-robot interaction  \n",
        "- Assistive technologies  \n",
        "- Image retrieval  \n",
        "- Visual question answering  \n",
        "\n",
        "By enabling open-vocabulary object detection, grounding allows models to be more flexible and responsive in real-world scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Grounding DINO Architecture**\n",
        "\n",
        "Grounding DINO extends the DINO architecture by incorporating a frozen language encoder (such as CLIP or BERT) into the detection framework. This enables the model to process textual descriptions and associate them with visual content.\n",
        "\n",
        "#### **Key Components:**\n",
        "- **Visual Backbone (e.g., Swin Transformer):**  \n",
        "  Extracts multi-scale visual features from the input image.\n",
        "\n",
        "- **Text Encoder (e.g., CLIP text encoder):**  \n",
        "  Encodes the input natural language query into a semantic embedding.\n",
        "\n",
        "- **Transformer Encoder-Decoder:**  \n",
        "  Aligns visual and textual features using a set of learnable object queries, similar to the standard DINO architecture.\n",
        "\n",
        "- **Cross-Modal Fusion:**  \n",
        "  Enhances interaction between visual and textual modalities to improve grounding performance.\n",
        "\n",
        "- **Prediction Heads:**  \n",
        "  Produce bounding boxes and corresponding confidence scores based on the aligned features.\n",
        "\n",
        "This architecture allows Grounding DINO to generalize to unseen object categories and referential expressions at test time, without requiring retraining for each new phrase. The model leverages large-scale pretrained vision-language models to handle open-vocabulary detection tasks effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Further Reading**\n",
        "\n",
        "For a further understanding of Grounding DINO's architecture, refer to the original paper:  \n",
        "📄 [Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection](https://arxiv.org/abs/2303.05499)\n",
        "\n",
        "---\n",
        "Proceed to the next cell to begin the implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH0bTjF7D5M6"
      },
      "source": [
        "### Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xAtNfgSkEDU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JevEe00wkb2b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA8VogRjED-Q"
      },
      "source": [
        "### Download Example Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we download rich example images with multiple objects in each, which makes them suitable for zero-shot object detection task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz3xOOuHEDcz"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!mkdir {HOME}/data\n",
        "%cd {HOME}/data\n",
        "\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ42-B1lG7Bu"
      },
      "source": [
        "You can use `visualiz_detections` function in order to visualize the detected objects with proper bounding boxes. The color of the bounding box is the same for objects with the same description. The number written above the bounding boxes describes the confidence level of the model about whether the description matches the detected object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk5Wzc6MC3L0"
      },
      "outputs": [],
      "source": [
        "def visualize_detections(image, boxes, text_labels, scores, font_size=24):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arialbd.ttf\", font_size)\n",
        "    except:\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "        except:\n",
        "            font = ImageFont.load_default()\n",
        "            if hasattr(font, 'size'):\n",
        "                font.size = font_size\n",
        "\n",
        "    color_palette = [\n",
        "        (255, 99, 132), (54, 162, 235), (255, 206, 86),\n",
        "        (75, 192, 192), (153, 102, 255), (255, 159, 64),\n",
        "        (0, 255, 127), (0, 191, 255), (255, 20, 147)\n",
        "    ]\n",
        "    color_map = {label: color_palette[i % len(color_palette)] for i, label in enumerate(set(text_labels))}\n",
        "\n",
        "    for box, label, score in zip(boxes, text_labels, scores):\n",
        "        color = color_map[label]\n",
        "        box = box.tolist()\n",
        "\n",
        "        draw.rectangle(box, outline=color, width=3)\n",
        "\n",
        "        label_text = f\"{label}: {score:.2f}\"\n",
        "\n",
        "        if hasattr(font, 'getbbox'):\n",
        "            text_bbox = font.getbbox(label_text)\n",
        "            text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
        "        else:\n",
        "            text_width, text_height = font.getsize(label_text)\n",
        "\n",
        "        padding_x = 10\n",
        "        padding_y = 4\n",
        "\n",
        "        text_bg = [\n",
        "            box[0] - 2,  # left\n",
        "            box[1] - text_height - 2*padding_y - 2,  # top\n",
        "            box[0] + text_width + 2*padding_x,  # right\n",
        "            box[1]  # bottom\n",
        "        ]\n",
        "\n",
        "        draw.rectangle(text_bg, fill=(0, 0, 0))\n",
        "\n",
        "        text_position = (\n",
        "            box[0] + padding_x - 2,  # x\n",
        "            box[1] - text_height - padding_y - 2  # y\n",
        "        )\n",
        "        draw.text(text_position, label_text, fill=(255, 255, 255), font=font)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCl5g3iqERuz"
      },
      "source": [
        "### Setup and Loading the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvs7IZNSEoM_"
      },
      "source": [
        "Load the Grounding DINO model and its corresponding processor here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO7uodCGlsaM"
      },
      "outputs": [],
      "source": [
        "model_id = \"IDEA-Research/grounding-dino-tiny\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# TODO: Initialize processor and model\n",
        "processor = ...\n",
        "model = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QKug5ixHaRO"
      },
      "source": [
        "Implement the `inference` function here. The purpose of this function is to use Grounding-DINO to detect the objects in the image based on the text prompt and show them if the threshold conditions were met. Pay attention to the fact that you might need to put the prompts variable inside brackets in order for the processor to work properly. This might vary based on implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kykmSnu1RESE"
      },
      "outputs": [],
      "source": [
        "def inference(processor, model, prompts, image_path, box_threshold=0.3, text_threshold=0.25):\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    # TODO: Preprocess the inputs using the processor\n",
        "    inputs = ...\n",
        "\n",
        "    # TODO: Generate the outputs\n",
        "    with torch.no_grad():\n",
        "      outputs = ...\n",
        "\n",
        "    # TODO: Using the processor and the generated outputs, generate the results containing boxes, text_labels and confidence scores\n",
        "    results = ...\n",
        "\n",
        "\n",
        "\n",
        "    result = results[0]\n",
        "    # TODO: Initialize boxes, text_labels and scores using the result\n",
        "    boxes = ...\n",
        "    text_labels = ...\n",
        "    scores = ...\n",
        "\n",
        "    visualized_image = visualize_detections(image.copy(), boxes, text_labels, scores)\n",
        "\n",
        "    plt.figure(figsize=(16, 18))\n",
        "    plt.imshow(visualized_image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Grounding DINO Detection\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zero-Shot Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5LrawFEH8Mq"
      },
      "source": [
        "From now on we will test this model on some examples. You are free to use any sort of prompts that satisfy you. Note that setting the correct threshold values plays an important role in how well the model can detect objects and how soft or hard it performs. Try to do trial-and-error with the prompt and the thresholds to understand the performance and limitations of Grounding DINO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV0zCvDUp8QI"
      },
      "outputs": [],
      "source": [
        "# TODO: Write suitable text prompts and set suitable values for thresholds\n",
        "image_name = \"dog-3.jpeg\"\n",
        "image_path = os.path.join(HOME, \"data\", image_name)\n",
        "prompts = [\"\"]\n",
        "\n",
        "box_threshold = ...\n",
        "text_threshold = ...\n",
        "\n",
        "inference(processor, model, prompts, image_path, box_threshold, text_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIJ9Diver4NS"
      },
      "outputs": [],
      "source": [
        "# TODO: Write suitable text prompts and set suitable values for thresholds\n",
        "image_name = \"dog-3.jpeg\"\n",
        "image_path = os.path.join(HOME, \"data\", image_name)\n",
        "prompts = [\"\"]\n",
        "\n",
        "box_threshold = ...\n",
        "text_threshold = ...\n",
        "\n",
        "inference(processor, model, prompts, image_path, box_threshold, text_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ih9TQrlvJZK"
      },
      "outputs": [],
      "source": [
        "# TODO: Write suitable text prompts and set suitable values for thresholds\n",
        "image_name = \"dog-2.jpeg\"\n",
        "image_path = os.path.join(HOME, \"data\", image_name)\n",
        "prompts = [\"\"]\n",
        "\n",
        "box_threshold = ...\n",
        "text_threshold = ...\n",
        "\n",
        "inference(processor, model, prompts, image_path, box_threshold, text_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqeagmHuvmm8"
      },
      "outputs": [],
      "source": [
        "# TODO: Write suitable text prompts and set suitable values for thresholds\n",
        "image_name = \"dog-2.jpeg\"\n",
        "image_path = os.path.join(HOME, \"data\", image_name)\n",
        "prompts = [\"\"]\n",
        "\n",
        "box_threshold = ...\n",
        "text_threshold = ...\n",
        "\n",
        "inference(processor, model, prompts, image_path, box_threshold, text_threshold)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
